{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosselinPerret/DataDrivenControl-EI/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense,TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "iwqrll12qtol"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ZtmA66JN3UPJ",
        "outputId": "d5fd86bb-6170-486a-d5ae-4ab8e5193d17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGNCSWFlps0I"
      },
      "outputs": [],
      "source": [
        "df_in = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/EI Data driven control/bdd_in_mat_05.csv')\n",
        "df_out = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/EI Data driven control/bdd_out_mat_05.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimension of df_in: {df_in.shape}\")\n",
        "print(f\"Dimension of df_out: {df_out.shape}\")"
      ],
      "metadata": {
        "id": "5W4jhnpqsbQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "on se place dans le cas où la voiture est immobile, donc il suffit de regarder une seule hélice."
      ],
      "metadata": {
        "id": "CxTbAAShtjwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the first temporal series (first row) from df_in\n",
        "first_temporal_series_in = df_in.iloc[0]\n",
        "\n",
        "# Extract the corresponding first temporal series from df_out\n",
        "first_temporal_series_out = df_out.iloc[0]\n",
        "\n",
        "# Convert to numpy arrays for plotting if preferred, or keep as pandas Series\n",
        "first_temporal_series_in_array = first_temporal_series_in.to_numpy()\n",
        "first_temporal_series_out_array = first_temporal_series_out.to_numpy()\n",
        "\n",
        "print(\"First temporal series from df_in (first 10 values):\")\n",
        "print(first_temporal_series_in_array[:10])\n",
        "print(f\"\\nLength of the df_in series: {len(first_temporal_series_in_array)}\")\n",
        "\n",
        "print(\"\\nFirst temporal series from df_out (first 10 values):\")\n",
        "print(first_temporal_series_out_array[:10])\n",
        "print(f\"\\nLength of the df_out series: {len(first_temporal_series_out_array)}\")\n",
        "\n",
        "# Plot both temporal series on the same graph\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(first_temporal_series_in_array, label='df_in - Input Series')\n",
        "plt.plot(first_temporal_series_out_array, label='df_out - Output Series')\n",
        "plt.title('First Temporal Series (Input and Output)')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xu1yizw5ru1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "for i in range(df_out.shape[0]):\n",
        "    plt.plot(df_out.iloc[i], alpha=0.5, label=f'Row {i}')\n",
        "\n",
        "plt.title('All Rows of df_out')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sf96lUydNIUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0406e7fc"
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(first_temporal_series_in_array, first_temporal_series_out_array, alpha=0.5)\n",
        "plt.title('Scatter Plot of First Temporal Series (df_in vs df_out)')\n",
        "plt.xlabel('df_in Value')\n",
        "plt.ylabel('df_out Value')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ad9a63c"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(first_temporal_series_in_array, bins=50, edgecolor='black')\n",
        "plt.title('Distribution of Values in first_temporal_series_in_array')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "la sortie est l'accéleration verticale d'ou le fait que ce soit -g lorsque la commande est 0\n",
        "\n",
        "l'entrée représente une commande normalisée surement le voltage"
      ],
      "metadata": {
        "id": "09V7XY44yNnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "il faudra integrer 2x"
      ],
      "metadata": {
        "id": "BhYm5vj03Ij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(first_temporal_series_out_array[:100])\n",
        "plt.title('First 100 Values of first_temporal_series_out_array')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcnhMzJ-y_E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "il faut environ 10 points entre 40 et 50 (T_s = 0.05s) soit entre 2s et 2.5s --> soit 0.5/10 = T_s ça justifie le temps d'échantillonnage --> il faut vérifier sur toutes les donénes"
      ],
      "metadata": {
        "id": "_U2X2D2hzlgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on va faire un réseau de neurone pour prédire l'accéleration puis on intégrera 2 fois pour obtenir la position car notre capteur est un accelerometre"
      ],
      "metadata": {
        "id": "qRjs5oxx3yA8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8947dcf2"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52fc3946"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "df_in_cleaned = df_in.copy()\n",
        "df_out_cleaned = df_out.copy()\n",
        "\n",
        "# Set the z_score_threshold\n",
        "z_score_threshold = 3\n",
        "\n",
        "z_scores_in = zscore(df_in_cleaned, axis=1, nan_policy='omit') # Calculate Z-scores for each row (time series)\n",
        "abs_z_scores_in = np.abs(z_scores_in)\n",
        "\n",
        "z_scores_out = zscore(df_out_cleaned, axis=1, nan_policy='omit')\n",
        "abs_z_scores_out = np.abs(z_scores_out)\n",
        "\n",
        "outlier_rows_in = (abs_z_scores_in > z_score_threshold).any(axis=1)\n",
        "outlier_rows_out = (abs_z_scores_out > z_score_threshold).any(axis=1)\n",
        "\n",
        "# Combine the identified outlier rows from both DataFrames\n",
        "total_outlier_rows = outlier_rows_in | outlier_rows_out\n",
        "# Create a boolean mask rows_to_keep by negating the total_outlier_rows\n",
        "rows_to_keep = ~total_outlier_rows\n",
        "\n",
        "# Filter both df_in_cleaned and df_out_cleaned using rows_to_keep\n",
        "df_in_cleaned = df_in_cleaned[rows_to_keep]\n",
        "df_out_cleaned = df_out_cleaned[rows_to_keep]\n",
        "\n",
        "print(f\"Original shape of df_in: {df_in.shape}\")\n",
        "print(f\"Original shape of df_out: {df_out.shape}\")\n",
        "print(f\"Number of rows identified as outliers: {np.sum(total_outlier_rows)}\")\n",
        "print(f\"Shape of cleaned df_in_cleaned: {df_in_cleaned.shape}\")\n",
        "print(f\"Shape of cleaned df_out_cleaned: {df_out_cleaned.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "for i in range(df_out_cleaned.shape[0]):\n",
        "    plt.plot(df_out_cleaned.iloc[i], alpha=0.5, label=f'Row {i}')\n",
        "\n",
        "plt.title('All Rows of df_out_cleaned')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EQBB31l5I6tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad4ee393"
      },
      "source": [
        "# Re-scale Input Data using the cleaned df_in_cleaned\n",
        "X = df_in_cleaned.to_numpy()\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "print(f\"\\nOriginal shape of X after outlier removal: {X.shape}\")\n",
        "print(f\"Shape of X_scaled after re-scaling: {X_scaled.shape}\")\n",
        "\n",
        "# Re-normalize Output Data using the cleaned df_out_cleaned\n",
        "y = df_out_cleaned.to_numpy()\n",
        "df_out_shifted = y - y[:, 0, np.newaxis]\n",
        "global_max_abs_y = np.max(np.abs(df_out_shifted))\n",
        "y_normalized = df_out_shifted / global_max_abs_y\n",
        "\n",
        "print(f\"\\nOriginal shape of y after outlier removal: {y.shape}\")\n",
        "print(f\"Shape of y_normalized after re-normalization: {y_normalized.shape}\")\n",
        "print(f\"New global maximum absolute value for y normalization: {global_max_abs_y}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6898669"
      },
      "source": [
        "# Reshape both the normalized input (X) and normalized output (y) arrays into a 3D format (samples, timesteps, features)\n",
        "# For this dataset, samples will be the number of rows, timesteps will be the number of columns, and features will be 1.\n",
        "\n",
        "n_samples_cleaned, n_timesteps = X_scaled.shape\n",
        "X_reshaped = X_scaled.reshape(n_samples_cleaned, n_timesteps, 1)\n",
        "\n",
        "y_reshaped = y_normalized.reshape(n_samples_cleaned, n_timesteps, 1)\n",
        "\n",
        "print(f\"Original shape of X_scaled: {X_scaled.shape}\")\n",
        "print(f\"Reshaped shape of X_reshaped: {X_reshaped.shape}\")\n",
        "print(f\"Original shape of y_normalized: {y_normalized.shape}\")\n",
        "print(f\"Reshaped shape of y_reshaped: {y_reshaped.shape}\")\n",
        "\n",
        "# Allocate 80% of the data for training and 20% for testing. Use train_test_split from sklearn.model_selection for this purpose.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "ZBGwf_c-IH5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Construction du modèle LSTM ---\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(n_timesteps, 1), return_sequences=True))\n",
        "model.add(Dense(1))  # prédiction par timestep\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "dMK5AGUl2g9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LF_vY-jaAyIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Entraînement ---\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# --- Évaluation ---\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")"
      ],
      "metadata": {
        "id": "C-3GKVRPJVEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "g = 9.81\n",
        "\n",
        "# Remettre à l’échelle d’origine\n",
        "y_pred_real = y_pred * global_max_abs_y - g\n",
        "y_test_real = y_test * global_max_abs_y - g\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_real.flatten(), y_pred_real.flatten()))\n",
        "print(f\"RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "mdNKcJN12pww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1  # indice du sample à visualiser\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot real and predicted output on the primary y-axis\n",
        "ax1.plot(y_test_real[i].squeeze()[:200], label=\"Réel (Output)\", color='blue')\n",
        "ax1.plot(y_pred_real[i].squeeze()[:200], label=\"Prédit (Output)\", color='red', linestyle='--')\n",
        "ax1.set_xlabel('Time Step')\n",
        "ax1.set_ylabel('Output Value (Acceleration)', color='blue')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "# Create a secondary y-axis for the input signal\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(X_test[i].squeeze()[:200], label=\"Input Signal\", color='green', alpha=0.7)\n",
        "ax2.set_ylabel('Input Value (Normalized Command)', color='green')\n",
        "ax2.tick_params(axis='y', labelcolor='green')\n",
        "\n",
        "# Add title and legend\n",
        "plt.title(\"Comparaison Input, sortie réelle vs prédite (Premiers 200 points)\")\n",
        "fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.9))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cT9pIWNg2rYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1  # vous pouvez changer cet indice\n",
        "\n",
        "# Données réelles\n",
        "real_acceleration = y_test_real[i].squeeze()\n",
        "# Données prédites\n",
        "predicted_acceleration = y_pred_real[i].squeeze()\n",
        "\n",
        "# Calcul de l'erreur d'accélération\n",
        "error_acceleration = np.abs(real_acceleration - predicted_acceleration)\n",
        "\n",
        "# Fonction pour calculer la position à partir de l'accélération\n",
        "def calculate_position(acceleration, dt=0.05):\n",
        "    velocity = np.cumsum(acceleration) * dt\n",
        "    position = np.cumsum(velocity) * dt\n",
        "    return position, velocity\n",
        "\n",
        "# Calculer les positions et vitesses\n",
        "real_position, real_velocity = calculate_position(real_acceleration)\n",
        "predicted_position, predicted_velocity = calculate_position(predicted_acceleration)\n",
        "\n",
        "# Affichage des résultats\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Accélération\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(real_acceleration, label='Accélération réelle', color='blue')\n",
        "plt.plot(predicted_acceleration, label='Accélération prédite', linestyle='--', color='red')\n",
        "plt.legend()\n",
        "plt.title('Comparaison des accélérations')\n",
        "plt.grid(True)\n",
        "\n",
        "# Erreur d'Accélération\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(error_acceleration, label='Erreur Absolue Accélération', linestyle=':', color='green')\n",
        "plt.legend()\n",
        "plt.title('Erreur Absolue d\\'Accélération')\n",
        "plt.grid(True)\n",
        "\n",
        "# Vitesse\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(real_velocity, label='Vitesse réelle')\n",
        "plt.plot(predicted_velocity, label='Vitesse prédite', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title('Comparaison des vitesses')\n",
        "plt.grid(True)\n",
        "\n",
        "# Position\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(real_position, label='Position réelle')\n",
        "plt.plot(predicted_position, label='Position prédite', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title('Comparaison des positions')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculer l'erreur RMS pour chaque variable\n",
        "def calculate_rmse(real, pred):\n",
        "    return np.sqrt(np.mean((real - pred) ** 2))\n",
        "\n",
        "print(f\"RMSE Accélération: {calculate_rmse(real_acceleration, predicted_acceleration):.4f}\")\n",
        "print(f\"RMSE Vitesse: {calculate_rmse(real_velocity, predicted_velocity):.4f}\")\n",
        "print(f\"RMSE Position: {calculate_rmse(real_position, predicted_position):.4f}\")"
      ],
      "metadata": {
        "id": "ZwY4KvkWAsKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "on a le modèle, on va comparer avec d'autres modèles"
      ],
      "metadata": {
        "id": "yl6VFsk3Cg0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SSM"
      ],
      "metadata": {
        "id": "lJViY2QFILiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find A B C"
      ],
      "metadata": {
        "id": "OvWrwlbEKldS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57f8dea1"
      },
      "source": [
        "import scipy.linalg\n",
        "\n",
        "# 2. Define the discrete-time state-space matrices A and B\n",
        "# State vector: [height, velocity]\n",
        "# Equations:\n",
        "# height(t+dt) = height(t) + velocity(t) * dt + 0.5 * acceleration(t) * dt^2\n",
        "# velocity(t+dt) = velocity(t) + acceleration(t) * dt\n",
        "\n",
        "dt = 0.05  # sampling time\n",
        "\n",
        "A = np.array([[1, dt],\n",
        "              [0, 1]])\n",
        "\n",
        "B = np.array([[0.5 * dt**2],\n",
        "              [dt]])\n",
        "\n",
        "# 3. Define the Q and R matrices\n",
        "# Q penalizes state deviations (height, velocity)\n",
        "# R penalizes control input (acceleration)\n",
        "Q = np.array([[10, 0],\n",
        "              [0, 1]]) # Penalize height more than velocity\n",
        "R = np.array([[0.1]]) # Penalize control input (acceleration) less\n",
        "\n",
        "# 4. Calculate the optimal feedback gain matrix K\n",
        "# Solve the Discrete Algebraic Riccati Equation (DARE) to find P\n",
        "P = scipy.linalg.solve_discrete_are(A, B, Q, R)\n",
        "\n",
        "# Calculate K using P\n",
        "K = np.linalg.inv(R + B.T @ P @ B) @ (B.T @ P @ A)\n",
        "\n",
        "print(\"State-space matrix A:\\n\", A)\n",
        "print(\"\\nState-space matrix B:\\n\", B)\n",
        "print(\"\\nCost matrix Q:\\n\", Q)\n",
        "print(\"\\nCost matrix R:\\n\", R)\n",
        "print(\"\\nOptimal feedback gain K:\\n\", K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9dc112c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 5. Set simulation parameters\n",
        "target_height = 10.0  # meters\n",
        "initial_height = 0.0  # meters\n",
        "initial_velocity = 0.0  # m/s\n",
        "simulation_duration = 20  # seconds\n",
        "\n",
        "num_steps = int(simulation_duration / dt)\n",
        "\n",
        "# 6. Initialize arrays to store results\n",
        "height_history = np.zeros(num_steps)\n",
        "velocity_history = np.zeros(num_steps)\n",
        "acceleration_history = np.zeros(num_steps)\n",
        "\n",
        "# Initial state\n",
        "x_current = np.array([[initial_height], [initial_velocity]])\n",
        "\n",
        "# 7. Implement simulation loop\n",
        "for i in range(num_steps):\n",
        "    # a. Calculate current state vector (already x_current)\n",
        "\n",
        "    # b. Determine the error state (current state minus target state)\n",
        "    # Target state: [target_height, 0]\n",
        "    error_state = x_current - np.array([[target_height], [0.0]])\n",
        "\n",
        "    # c. Compute the control input u (acceleration)\n",
        "    u = -K @ error_state\n",
        "\n",
        "    # d. Update the system's state using the discrete-time state-space equations\n",
        "    x_current = A @ x_current + B @ u\n",
        "\n",
        "    # e. Store the current height, velocity, and control input\n",
        "    height_history[i] = x_current[0, 0]\n",
        "    velocity_history[i] = x_current[1, 0]\n",
        "    acceleration_history[i] = u[0, 0]\n",
        "\n",
        "# Plotting the results\n",
        "time = np.linspace(0, simulation_duration, num_steps)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(time, height_history)\n",
        "plt.axhline(y=target_height, color='r', linestyle='--', label='Target Height')\n",
        "plt.title('Height over Time')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Height (m)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(time, velocity_history)\n",
        "plt.title('Velocity over Time')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Velocity (m/s)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(time, acceleration_history)\n",
        "plt.title('Controller Output (Acceleration) over Time')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Acceleration (m/s^2)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trop dur de trouver le modèle inverse donc on fait optimization based LSTM contrller"
      ],
      "metadata": {
        "id": "GMriYOqRPk3K"
      }
    }
  ]
}