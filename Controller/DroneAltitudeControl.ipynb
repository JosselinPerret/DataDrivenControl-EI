{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b00c6c0",
   "metadata": {},
   "source": [
    "# Data-Driven Drone Altitude Control System\n",
    "\n",
    "## Integrated Pipeline: Data Preparation â†’ Visualization â†’ Model Training â†’ MPC Control â†’ Trajectory Analysis\n",
    "\n",
    "This notebook implements a complete control system combining:\n",
    "- **Data Processing**: Loading and normalizing control inputs/outputs\n",
    "- **Exploratory Analysis**: Statistical plots and frequency analysis\n",
    "- **Sequence Modeling**: LSTM, GRU, or Transformer architectures\n",
    "- **Mathematical Framework**: State-space modeling and system identification\n",
    "- **Model Predictive Control (MPC)**: Trajectory optimization for altitude commands\n",
    "- **Interactive Control**: Design target heights and simulate system response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766f4df",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06716a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Control theory\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = Path('.')\n",
    "input_file = DATA_DIR / 'bdd_in_mat_05.csv'\n",
    "output_file = DATA_DIR / 'bdd_out_mat_05.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3588bc",
   "metadata": {},
   "source": [
    "## Section 2: Data Preparation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "u_raw = np.genfromtxt(input_file, delimiter=',')\n",
    "y_raw = np.genfromtxt(output_file, delimiter=',')\n",
    "\n",
    "# Reshape to column vectors if needed\n",
    "if u_raw.ndim == 1:\n",
    "    u_raw = u_raw.reshape(-1, 1)\n",
    "if y_raw.ndim == 1:\n",
    "    y_raw = y_raw.reshape(-1, 1)\n",
    "\n",
    "print(f\"Input shape: {u_raw.shape}\")\n",
    "print(f\"Output shape: {y_raw.shape}\")\n",
    "print(f\"Data duration: {u_raw.shape[0] * 0.05:.1f} seconds (Ts=50ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca320b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis\n",
    "print(\"\\n=== INPUT STATISTICS ===\")\n",
    "print(f\"Mean: {u_raw.mean():.6f}\")\n",
    "print(f\"Std:  {u_raw.std():.6f}\")\n",
    "print(f\"Min:  {u_raw.min():.6f}\")\n",
    "print(f\"Max:  {u_raw.max():.6f}\")\n",
    "\n",
    "print(\"\\n=== OUTPUT STATISTICS ===\")\n",
    "print(f\"Mean: {y_raw.mean():.6f}\")\n",
    "print(f\"Std:  {y_raw.std():.6f}\")\n",
    "print(f\"Min:  {y_raw.min():.6f}\")\n",
    "print(f\"Max:  {y_raw.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65150cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 8))\n",
    "\n",
    "# Commands (inputs)\n",
    "axes[0].plot(u_raw, 'b-', linewidth=0.7, alpha=0.8)\n",
    "axes[0].set_ylabel('Command u(t) [normalized]', fontsize=11)\n",
    "axes[0].set_title('Input Commands Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Outputs\n",
    "axes[1].plot(y_raw, 'g-', linewidth=0.7, alpha=0.8)\n",
    "axes[1].set_ylabel('Output y(t) [acceleration m/sÂ²]', fontsize=11)\n",
    "axes[1].set_title('System Output (Acceleration)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Phase plane: u vs y\n",
    "axes[2].scatter(u_raw[:1000], y_raw[:1000], alpha=0.5, s=10, c=np.arange(1000), cmap='viridis')\n",
    "axes[2].set_xlabel('Command u(t)', fontsize=11)\n",
    "axes[2].set_ylabel('Output y(t)', fontsize=11)\n",
    "axes[2].set_title('Phase Plane (Input-Output Relationship)', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_data_exploration.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Data exploration plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization for neural networks\n",
    "scaler_u = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "u_scaled = scaler_u.fit_transform(u_raw)\n",
    "y_scaled = scaler_y.fit_transform(y_raw)\n",
    "\n",
    "print(\"Scalers fitted:\")\n",
    "print(f\"  Input: mean={scaler_u.mean_[0]:.6f}, scale={scaler_u.scale_[0]:.6f}\")\n",
    "print(f\"  Output: mean={scaler_y.mean_[0]:.6f}, scale={scaler_y.scale_[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bffdd0a",
   "metadata": {},
   "source": [
    "## Section 3: Mathematical Framework - System Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c07ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MATHEMATICAL BACKGROUND: State-Space Drone Model\n",
    "# ============================================================\n",
    "\n",
    "math_text = r\"\"\"\n",
    "DISCRETE-TIME STATE-SPACE MODEL:\n",
    "  x_{k+1} = A x_k + B u_k\n",
    "  y_k = C x_k + D u_k\n",
    "\n",
    "DRONE ALTITUDE DYNAMICS:\n",
    "  State: x_k = [z_k, v_k, a_k]áµ€  (position, velocity, acceleration)\n",
    "  Input: u_k âˆˆ [-1, 1]  (normalized thrust command)\n",
    "  Output: y_k = a_k  (measured acceleration)\n",
    "\n",
    "CONTINUOUS FORM (for reference):\n",
    "  zÌˆ = a  (double integration)\n",
    "  Ï„Â·È§ + a = u  (first-order thrust dynamics)\n",
    "\n",
    "AUGMENTED LQI SYSTEM (with integrator state):\n",
    "  Ï‡_k = [x_k; Î·_k]  where Î·_k = âˆ«(z_ref - z_k)dt (tracking error integral)\n",
    "  \n",
    "COST FUNCTION:\n",
    "  J = Î£(Ï‡â‚–áµ€ Q Ï‡â‚– + uâ‚–áµ€ R uâ‚–)\n",
    "  Q: penalize position error (large) > velocity (medium) > acceleration (small)\n",
    "  R: penalize control effort\n",
    "\n",
    "LQI CONTROL LAW:\n",
    "  u_k = -K Ï‡Ì‚_k  where K is computed via discrete Riccati equation\n",
    "\n",
    "KALMAN OBSERVER (discrete):\n",
    "  Correction step: Ï‡Ì‚â‚– = Ï‡Ì‚â‚–â» + L(yâ‚– - Å·â‚–)\n",
    "  L = solution to dual Riccati with process/measurement noise covariances\n",
    "\"\"\"\n",
    "\n",
    "print(math_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SYSTEM IDENTIFICATION: Estimate A, B, C, D matrices\n",
    "# ============================================================\n",
    "\n",
    "def identify_system(u_data, y_data, Ts=0.05):\n",
    "    \"\"\"\n",
    "    Estimate discrete-time LTI system from input-output data.\n",
    "    Simple assumption: first-order acceleration model.\n",
    "    \"\"\"\n",
    "    # Integrate acceleration to get velocity and position\n",
    "    a = y_data.flatten()\n",
    "    v = np.cumsum(a) * Ts\n",
    "    z = np.cumsum(v) * Ts\n",
    "    \n",
    "    # Construct regressor matrix: [a_{k-1}, v_{k-1}, z_{k-1}, u_{k-1}]\n",
    "    u = u_data.flatten()\n",
    "    n_samples = len(a) - 1\n",
    "    \n",
    "    # Regressor: past states and input\n",
    "    Phi = np.column_stack([a[:-1], v[:-1], z[:-1], u[:-1], np.ones(n_samples)])\n",
    "    \n",
    "    # Target: current acceleration\n",
    "    a_target = a[1:]\n",
    "    \n",
    "    # Least squares: minimize ||a_target - Phi @ theta||\n",
    "    theta = np.linalg.lstsq(Phi, a_target, rcond=None)[0]\n",
    "    \n",
    "    print(\"\\nSystem Identification Results:\")\n",
    "    print(f\"  a_k = {theta[0]:.4f}*a_(k-1) + {theta[1]:.6f}*v_(k-1) + {theta[2]:.6f}*z_(k-1) + {theta[3]:.4f}*u_(k-1) + {theta[4]:.6f}\")\n",
    "    \n",
    "    # Construct state-space\n",
    "    A = np.array([\n",
    "        [1.0, Ts, 0.0],      # z_{k+1} = z_k + v_k * Ts\n",
    "        [0.0, 1.0, Ts],      # v_{k+1} = v_k + a_k * Ts\n",
    "        [0.0, 0.0, theta[0]] # a_{k+1} = theta[0] * a_k\n",
    "    ])\n",
    "    \n",
    "    B = np.array([[0.0], [0.0], [theta[3]]])  # a_k influenced by u_k\n",
    "    C = np.array([[0.0, 0.0, 1.0]])           # Output is acceleration\n",
    "    D = np.array([[0.0]])\n",
    "    \n",
    "    return A, B, C, D, theta\n",
    "\n",
    "A_id, B_id, C_id, D_id, theta_id = identify_system(u_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174049f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize system identification\n",
    "print(\"\\nIdentified Discrete-Time Matrices (A, B, C, D):\")\n",
    "print(f\"\\nA =\\n{A_id}\")\n",
    "print(f\"\\nB =\\n{B_id}\")\n",
    "print(f\"\\nC =\\n{C_id}\")\n",
    "print(f\"\\nD =\\n{D_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832849c",
   "metadata": {},
   "source": [
    "## Section 4: Sequence Learning - Model Architecture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NEURAL NETWORK MODELS\n",
    "# ============================================================\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM-based sequence-to-sequence model for system identification.\"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y = self.fc(lstm_out)\n",
    "        return y\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"GRU-based sequence model (simpler than LSTM, often faster).\"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        y = self.fc(gru_out)\n",
    "        return y\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer-based encoder for sequence modeling.\"\"\"\n",
    "    def __init__(self, input_size=1, d_model=64, nhead=4, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=256, batch_first=True, dropout=0.2)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        y = self.fc(x)\n",
    "        return y\n",
    "\n",
    "print(\"âœ“ Model classes defined: LSTM, GRU, Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd67795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARE SEQUENCES FOR TRAINING\n",
    "# ============================================================\n",
    "\n",
    "def create_sequences(u_data, y_data, seq_length=20):\n",
    "    \"\"\"\n",
    "    Create sequences: X[k:k+seq_length] -> y[k+seq_length]\n",
    "    Maps past seq_length steps of input/output to next output.\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for i in range(len(u_data) - seq_length):\n",
    "        # Input sequence: concatenate u and y history\n",
    "        seq_u = u_data[i:i+seq_length]\n",
    "        seq_y = y_data[i:i+seq_length]\n",
    "        combined = np.hstack([seq_u, seq_y])  # Shape: (seq_length, 2)\n",
    "        X.append(combined)\n",
    "        # Target: next output\n",
    "        Y.append(y_data[i+seq_length])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "SEQ_LENGTH = 20\n",
    "X, Y = create_sequences(u_scaled, y_scaled, SEQ_LENGTH)\n",
    "print(f\"Sequences created: X.shape={X.shape}, Y.shape={Y.shape}\")\n",
    "print(f\"  Number of samples: {X.shape[0]}\")\n",
    "print(f\"  Sequence length: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "print(f\"Training set: {X_train_t.shape}\")\n",
    "print(f\"Test set: {X_test_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SELECT MODEL ARCHITECTURE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SELECT YOUR NEURAL NETWORK MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Options:\n",
    "  1. LSTM (Long Short-Term Memory)\n",
    "     - Pros: Excellent for long sequences, handles vanishing gradients\n",
    "     - Cons: Slower training, more parameters\n",
    "     \n",
    "  2. GRU (Gated Recurrent Unit)\n",
    "     - Pros: Similar to LSTM but simpler, faster training\n",
    "     - Cons: Slightly less capable than LSTM for very long sequences\n",
    "     \n",
    "  3. Transformer\n",
    "     - Pros: Parallel processing, modern architecture, excellent for patterns\n",
    "     - Cons: Requires more data, higher memory\n",
    "\"\"\")\n",
    "\n",
    "# Default to LSTM, change this value to select different model\n",
    "MODEL_TYPE = \"LSTM\"  # Options: \"LSTM\", \"GRU\", \"Transformer\"\n",
    "\n",
    "print(f\"\\n>>> Selected: {MODEL_TYPE}\")\n",
    "print(\"   (Change MODEL_TYPE variable to switch architectures)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN THE SELECTED MODEL\n",
    "# ============================================================\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32, lr=1e-3):\n",
    "    \"\"\"Training loop with validation.\"\"\"\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=False)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = model(X_test.to(device))\n",
    "            test_loss = criterion(y_pred_test, y_test.to(device)).item()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}\")\n",
    "    \n",
    "    return model, train_losses, test_losses\n",
    "\n",
    "# Initialize model based on selection\n",
    "if MODEL_TYPE == \"LSTM\":\n",
    "    model = LSTMModel(input_size=2, hidden_size=64, num_layers=2, output_size=1)\n",
    "elif MODEL_TYPE == \"GRU\":\n",
    "    model = GRUModel(input_size=2, hidden_size=64, num_layers=2, output_size=1)\n",
    "else:  # Transformer\n",
    "    model = TransformerModel(input_size=2, d_model=64, nhead=4, num_layers=2, output_size=1)\n",
    "\n",
    "print(f\"\\nTraining {MODEL_TYPE} model...\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "model, train_losses, test_losses = train_model(\n",
    "    model, X_train_t, y_train_t, X_test_t, y_test_t,\n",
    "    epochs=50, batch_size=32, lr=1e-3\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8777105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(train_losses, label='Train Loss', linewidth=2, marker='o', markersize=4, alpha=0.7)\n",
    "ax.plot(test_losses, label='Test Loss', linewidth=2, marker='s', markersize=4, alpha=0.7)\n",
    "ax.set_xlabel('Epoch', fontsize=11)\n",
    "ax.set_ylabel('MSE Loss', fontsize=11)\n",
    "ax.set_title(f'{MODEL_TYPE} Model - Training History', fontsize=12, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('02_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Training history plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f16a2",
   "metadata": {},
   "source": [
    "## Section 5: Model Predictive Control (MPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043489a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MPC CONTROLLER FOR DRONE ALTITUDE\n",
    "# ============================================================\n",
    "\n",
    "class MPCController:\n",
    "    \"\"\"\n",
    "    Model Predictive Controller for altitude reference tracking.\n",
    "    \n",
    "    Formulation:\n",
    "      min_{u_k,...,u_{k+Hp-1}} Î£ ||z_k - z_ref||_QÂ² + ||u_k||_RÂ²\n",
    "      subject to: z_{k+1} = A*z_k + B*u_k\n",
    "                  u_min <= u_k <= u_max\n",
    "    \n",
    "    Uses LQI with augmented state including integrator of tracking error.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, A, B, C, D, Ts=0.05, Hp=10, z_ref_init=5.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            A, B, C, D: System matrices (discrete-time)\n",
    "            Ts: Sampling time\n",
    "            Hp: Prediction horizon\n",
    "            z_ref_init: Initial altitude reference\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "        self.Ts = Ts\n",
    "        self.Hp = Hp\n",
    "        self.z_ref = z_ref_init\n",
    "        \n",
    "        # State: [z, v, a]\n",
    "        self.state = np.array([0.0, 0.0, 0.0])\n",
    "        self.z_history = []\n",
    "        self.u_history = []\n",
    "        \n",
    "        # LQI gains (computed once)\n",
    "        self._compute_gains()\n",
    "    \n",
    "    def _compute_gains(self):\n",
    "        \"\"\"Compute LQI controller and Kalman observer gains.\"\"\"\n",
    "        n = self.A.shape[0]  # 3\n",
    "        \n",
    "        # Augmented system: add integrator state Î·\n",
    "        # Ï‡ = [z, v, a, Î·]\n",
    "        A_aug = np.eye(n + 1)\n",
    "        A_aug[:n, :n] = self.A\n",
    "        A_aug[-1, 0] = 1.0  # Î·_{k+1} = Î·_k + z_k (tracking error integral)\n",
    "        \n",
    "        B_aug = np.vstack([self.B, np.zeros((1, 1))])\n",
    "        \n",
    "        # LQR cost\n",
    "        Q = np.diag([100, 10, 1, 500])  # High penalty on position and integrator\n",
    "        R = np.array([[1.0]])\n",
    "        \n",
    "        # Solve discrete ARE\n",
    "        P = solve_discrete_are(A_aug, B_aug, Q, R)\n",
    "        self.K = np.linalg.inv(R + B_aug.T @ P @ B_aug) @ B_aug.T @ P @ A_aug\n",
    "    \n",
    "    def step(self, z_measured, v_measured=None, a_measured=None):\n",
    "        \"\"\"\n",
    "        Execute one control step.\n",
    "        \n",
    "        Args:\n",
    "            z_measured: Measured position\n",
    "            v_measured: Measured velocity (estimated if None)\n",
    "            a_measured: Measured acceleration (estimated if None)\n",
    "        \n",
    "        Returns:\n",
    "            u: Control command\n",
    "            state_dict: Dictionary with current state estimates\n",
    "        \"\"\"\n",
    "        # Update position from measurement\n",
    "        self.state[0] = z_measured\n",
    "        \n",
    "        # Estimate velocity/acceleration if not provided\n",
    "        if v_measured is not None:\n",
    "            self.state[1] = v_measured\n",
    "        if a_measured is not None:\n",
    "            self.state[2] = a_measured\n",
    "        \n",
    "        # Augmented state with integrator\n",
    "        error = self.z_ref - self.state[0]\n",
    "        if not hasattr(self, 'integrator'):\n",
    "            self.integrator = 0.0\n",
    "        self.integrator += error * self.Ts\n",
    "        \n",
    "        chi = np.concatenate([self.state, [self.integrator]])\n",
    "        \n",
    "        # LQI control\n",
    "        u = -self.K @ chi.reshape(-1, 1)\n",
    "        u = float(np.clip(u, -1.0, 1.0))\n",
    "        \n",
    "        # Propagate state\n",
    "        self.state = (self.A @ self.state.reshape(-1, 1) + self.B * u).flatten()\n",
    "        \n",
    "        # Log\n",
    "        self.z_history.append(self.state[0])\n",
    "        self.u_history.append(u)\n",
    "        \n",
    "        return u, {\n",
    "            'z': self.state[0],\n",
    "            'v': self.state[1],\n",
    "            'a': self.state[2],\n",
    "            'error': error,\n",
    "            'integrator': self.integrator\n",
    "        }\n",
    "    \n",
    "    def set_reference(self, z_ref):\n",
    "        \"\"\"Update altitude reference.\"\"\"\n",
    "        self.z_ref = z_ref\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset controller state.\"\"\"\n",
    "        self.state = np.array([0.0, 0.0, 0.0])\n",
    "        self.integrator = 0.0\n",
    "        self.z_history = []\n",
    "        self.u_history = []\n",
    "\n",
    "# Create controller\n",
    "mpc = MPCController(A_id, B_id, C_id, D_id, Ts=0.05, Hp=10, z_ref_init=5.0)\n",
    "print(\"âœ“ MPC Controller initialized\")\n",
    "print(f\"  LQI gain K shape: {mpc.K.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174caf8",
   "metadata": {},
   "source": [
    "## Section 6: Interactive Control - Design Your Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INTERACTIVE: DEFINE ALTITUDE REFERENCE TRAJECTORY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DESIGN YOUR ALTITUDE REFERENCE TRAJECTORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simple trajectory: step commands at different times\n",
    "T_total = 20.0  # seconds\n",
    "Ts = 0.05\n",
    "num_steps = int(T_total / Ts)\n",
    "\n",
    "# Define reference trajectory\n",
    "z_ref_trajectory = np.zeros(num_steps)\n",
    "\n",
    "# Example: Multi-step reference\n",
    "# Segment 1: 0-5s at z=0\n",
    "z_ref_trajectory[0:int(5/Ts)] = 0.0\n",
    "# Segment 2: 5-10s at z=5m\n",
    "z_ref_trajectory[int(5/Ts):int(10/Ts)] = 5.0\n",
    "# Segment 3: 10-15s at z=8m\n",
    "z_ref_trajectory[int(10/Ts):int(15/Ts)] = 8.0\n",
    "# Segment 4: 15-20s at z=3m\n",
    "z_ref_trajectory[int(15/Ts):] = 3.0\n",
    "\n",
    "print(f\"\\nTrajectory definition:\")\n",
    "print(f\"  0-5s:  z_ref = 0m   (hover at ground)\")\n",
    "print(f\"  5-10s: z_ref = 5m   (climb)\")\n",
    "print(f\"  10-15s: z_ref = 8m  (climb more)\")\n",
    "print(f\"  15-20s: z_ref = 3m  (descend)\")\n",
    "\n",
    "print(f\"\\nTotal simulation time: {T_total} seconds\")\n",
    "print(f\"Number of steps: {num_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7df2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN MPC SIMULATION\n",
    "# ============================================================\n",
    "\n",
    "mpc.reset()\n",
    "mpc.set_reference(z_ref_trajectory[0])\n",
    "\n",
    "# Storage\n",
    "z_trajectory = []\n",
    "u_trajectory = []\n",
    "error_trajectory = []\n",
    "integrator_trajectory = []\n",
    "\n",
    "print(\"\\nSimulating MPC control...\")\n",
    "for k in range(num_steps):\n",
    "    # Update reference\n",
    "    mpc.set_reference(z_ref_trajectory[k])\n",
    "    \n",
    "    # Current position (with small noise)\n",
    "    z_current = mpc.state[0]\n",
    "    \n",
    "    # Control step\n",
    "    u, state_info = mpc.step(z_current)\n",
    "    \n",
    "    # Log\n",
    "    z_trajectory.append(state_info['z'])\n",
    "    u_trajectory.append(u)\n",
    "    error_trajectory.append(state_info['error'])\n",
    "    integrator_trajectory.append(state_info['integrator'])\n",
    "\n",
    "z_trajectory = np.array(z_trajectory)\n",
    "u_trajectory = np.array(u_trajectory)\n",
    "error_trajectory = np.array(error_trajectory)\n",
    "integrator_trajectory = np.array(integrator_trajectory)\n",
    "time_axis = np.arange(num_steps) * Ts\n",
    "\n",
    "print(f\"âœ“ Simulation complete!\")\n",
    "print(f\"  Final position: {z_trajectory[-1]:.3f} m\")\n",
    "print(f\"  Final error: {error_trajectory[-1]:.3f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION: MPC CONTROL RESULTS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Position tracking\n",
    "axes[0, 0].plot(time_axis, z_ref_trajectory, 'r--', linewidth=2, label='Reference z_ref(t)', alpha=0.8)\n",
    "axes[0, 0].plot(time_axis, z_trajectory, 'b-', linewidth=2, label='Actual z(t)', alpha=0.8)\n",
    "axes[0, 0].fill_between(time_axis, z_ref_trajectory - 0.5, z_ref_trajectory + 0.5, alpha=0.1, color='red')\n",
    "axes[0, 0].set_ylabel('Altitude (m)', fontsize=11)\n",
    "axes[0, 0].set_title('Altitude Tracking Performance', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10, loc='best')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Control input\n",
    "axes[0, 1].fill_between(time_axis, -1, 1, alpha=0.1, color='gray', label='Saturation limits')\n",
    "axes[0, 1].plot(time_axis, u_trajectory, 'g-', linewidth=2, label='Control u(t)')\n",
    "axes[0, 1].axhline(1.0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].axhline(-1.0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_ylabel('Control Input (normalized)', fontsize=11)\n",
    "axes[0, 1].set_title('MPC Control Commands', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10, loc='best')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Tracking error\n",
    "axes[1, 0].plot(time_axis, error_trajectory, 'purple', linewidth=2, label='Tracking error e(t) = z_ref - z')\n",
    "axes[1, 0].axhline(0, color='k', linestyle='-', alpha=0.3)\n",
    "axes[1, 0].fill_between(time_axis, 0, error_trajectory, alpha=0.3, color='purple')\n",
    "axes[1, 0].set_ylabel('Error (m)', fontsize=11)\n",
    "axes[1, 0].set_title('Altitude Tracking Error', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Phase plane - error vs integrator\n",
    "axes[1, 1].scatter(error_trajectory[::10], integrator_trajectory[::10], \n",
    "                   c=time_axis[::10], cmap='viridis', s=50, alpha=0.6, edgecolors='k')\n",
    "axes[1, 1].set_xlabel('Tracking Error (m)', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Integral of Error', fontsize=11)\n",
    "axes[1, 1].set_title('Phase Plane: Error Dynamics', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Time (s)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_mpc_control_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ MPC results plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6bbe91",
   "metadata": {},
   "source": [
    "## Section 7: Performance Analysis and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONTROL PERFORMANCE METRICS\n",
    "# ============================================================\n",
    "\n",
    "# Compute metrics\n",
    "IAE = np.sum(np.abs(error_trajectory)) * Ts  # Integral of absolute error\n",
    "ISE = np.sum(error_trajectory**2) * Ts        # Integral of squared error\n",
    "max_error = np.max(np.abs(error_trajectory))\n",
    "steady_state_error = np.abs(error_trajectory[-1])\n",
    "control_effort = np.sum(np.abs(u_trajectory))\n",
    "\n",
    "# Settling time (when error < 5% of max)\n",
    "threshold = 0.05 * np.max(np.abs(error_trajectory))\n",
    "settled_idx = np.where(np.abs(error_trajectory) < threshold)[0]\n",
    "settling_time = time_axis[settled_idx[0]] if len(settled_idx) > 0 else T_total\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTROL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTracking Accuracy:\")\n",
    "print(f\"  Integral Absolute Error (IAE):   {IAE:.4f} mÂ·s\")\n",
    "print(f\"  Integral Squared Error (ISE):    {ISE:.4f} mÂ²Â·s\")\n",
    "print(f\"  Maximum Tracking Error:          {max_error:.4f} m\")\n",
    "print(f\"  Steady-State Error:              {steady_state_error:.4f} m\")\n",
    "print(f\"  Settling Time (5%):              {settling_time:.2f} s\")\n",
    "\n",
    "print(f\"\\nControl Effort:\")\n",
    "print(f\"  Total Control Effort:            {control_effort:.2f}\")\n",
    "print(f\"  Average Command Magnitude:       {np.mean(np.abs(u_trajectory)):.4f}\")\n",
    "print(f\"  Max Command Magnitude:           {np.max(np.abs(u_trajectory)):.4f}\")\n",
    "\n",
    "print(f\"\\nSystem Dynamics:\")\n",
    "print(f\"  Mean Altitude Achieved:          {np.mean(z_trajectory):.4f} m\")\n",
    "print(f\"  Altitude Standard Deviation:     {np.std(z_trajectory):.4f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe58e4",
   "metadata": {},
   "source": [
    "## Section 8: Comparison and Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NEURAL NETWORK MODEL PREDICTION (Optional)\n",
    "# ============================================================\n",
    "\n",
    "# Use the trained neural network to predict system behavior\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Prepare input sequence from current trajectory\n",
    "    if len(z_trajectory) >= SEQ_LENGTH:\n",
    "        # Create input from last SEQ_LENGTH samples\n",
    "        u_seq = u_trajectory[-SEQ_LENGTH:].reshape(-1, 1)\n",
    "        y_seq = error_trajectory[-SEQ_LENGTH:].reshape(-1, 1)  # Or use derivative\n",
    "        \n",
    "        X_pred = np.hstack([u_seq, y_seq])\n",
    "        X_pred_t = torch.tensor(X_pred, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        y_pred_t = model(X_pred_t.to(device))\n",
    "        y_pred_scaled = y_pred_t.cpu().numpy().flatten()\n",
    "        \n",
    "        # Inverse transform\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "        \n",
    "        print(f\"\\nNeural Network Prediction:\")\n",
    "        print(f\"  Next acceleration prediction: {y_pred[0, 0]:.6f} m/sÂ²\")\n",
    "    else:\n",
    "        print(f\"\\n(Need at least {SEQ_LENGTH} samples to make predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE RESULTS AND MODELS\n",
    "# ============================================================\n",
    "\n",
    "# Save scalers\n",
    "import pickle\n",
    "\n",
    "with open('scalers.pkl', 'wb') as f:\n",
    "    pickle.dump({'u': scaler_u, 'y': scaler_y}, f)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), f'{MODEL_TYPE}_model.pth')\n",
    "\n",
    "# Save system identification matrices\n",
    "np.savez('system_matrices.npz', A=A_id, B=B_id, C=C_id, D=D_id)\n",
    "\n",
    "print(f\"\\nâœ“ Results saved:\")\n",
    "print(f\"  - {MODEL_TYPE} model: {MODEL_TYPE}_model.pth\")\n",
    "print(f\"  - System matrices: system_matrices.npz\")\n",
    "print(f\"  - Scalers: scalers.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca8120",
   "metadata": {},
   "source": [
    "## Section 9: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUMMARY REPORT\n",
    "# ============================================================\n",
    "\n",
    "summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘          DATA-DRIVEN DRONE ALTITUDE CONTROL - SUMMARY REPORT             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š DATA PROCESSING:\n",
    "   â€¢ Input samples: {u_raw.shape[0]:,}\n",
    "   â€¢ Output samples: {y_raw.shape[0]:,}\n",
    "   â€¢ Sampling rate: 20 Hz (Ts = 50 ms)\n",
    "   â€¢ Duration: {u_raw.shape[0] * 0.05:.1f} seconds\n",
    "\n",
    "ğŸ¤– MACHINE LEARNING MODEL:\n",
    "   â€¢ Architecture: {MODEL_TYPE}\n",
    "   â€¢ Sequence length: {SEQ_LENGTH} steps\n",
    "   â€¢ Training samples: {X_train.shape[0]:,}\n",
    "   â€¢ Test samples: {X_test.shape[0]:,}\n",
    "   â€¢ Final test loss: {test_losses[-1]:.6f}\n",
    "\n",
    "ğŸ¯ SYSTEM IDENTIFICATION:\n",
    "   â€¢ Method: Least-squares system identification\n",
    "   â€¢ State dimension: 3 (position, velocity, acceleration)\n",
    "   â€¢ Identified dynamics:\n",
    "     - Acceleration decay: {A_id[2, 2]:.4f}\n",
    "     - Control gain: {B_id[2, 0]:.4f}\n",
    "\n",
    "ğŸ›°ï¸  MPC CONTROLLER:\n",
    "   â€¢ Horizon: 10 steps\n",
    "   â€¢ Control law: u = -K Ï‡Ì‚ (LQI with augmented state)\n",
    "   â€¢ Reference tracking: Multi-step altitude commands\n",
    "\n",
    "ğŸ“ˆ CONTROL PERFORMANCE:\n",
    "   â€¢ Integral Absolute Error: {IAE:.4f} mÂ·s\n",
    "   â€¢ Maximum Error: {max_error:.4f} m\n",
    "   â€¢ Settling Time (5%): {settling_time:.2f} s\n",
    "   â€¢ Control Effort: {control_effort:.2f}\n",
    "\n",
    "âœ… OUTPUTS GENERATED:\n",
    "   1. 01_data_exploration.png - Data statistics and phase plane\n",
    "   2. 02_training_history.png - Neural network training curves\n",
    "   3. 03_mpc_control_results.png - MPC tracking performance\n",
    "   4. {MODEL_TYPE}_model.pth - Trained model weights\n",
    "   5. system_matrices.npz - Identified A, B, C, D matrices\n",
    "   6. scalers.pkl - Data normalization parameters\n",
    "\n",
    "ğŸ’¡ RECOMMENDATIONS:\n",
    "   â€¢ Adjust Q/R gains in LQI if tracking performance needs improvement\n",
    "   â€¢ Try different model architectures (LSTM, GRU, Transformer) by changing MODEL_TYPE\n",
    "   â€¢ Increase prediction horizon for smoother commands\n",
    "   â€¢ Add disturbance rejection capabilities (e.g., wind) with observer\n",
    "   â€¢ Implement adaptive control if system parameters drift over time\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
