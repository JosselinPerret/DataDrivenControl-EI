{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4024f1",
   "metadata": {},
   "source": [
    "# State Space Models (SSM) and LQ Control: Theory & Practice\n",
    "\n",
    "**Comprehensive notebook on advanced control system design:**\n",
    "- State Space Model formulation and discretization methods\n",
    "- Linear Quadratic Regulator (LQR) control design\n",
    "- SSM with learnable parameters (neural state space models)\n",
    "- System identification from experimental data (2×2 model)\n",
    "- LQI control with Kalman observer for robust tracking\n",
    "- Hybrid LQR + Learning architecture\n",
    "- Performance metrics and comparative analysis\n",
    "\n",
    "**Data:** Drone altitude control (acceleration commands → altitude tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1427c",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "from scipy.linalg import solve_discrete_are\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ All imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING AND CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "# Load experimental data\n",
    "print(\"Loading experimental data...\")\n",
    "data_in = np.loadtxt('bdd_in_mat_05.csv', delimiter=',')\n",
    "data_out = np.loadtxt('bdd_out_mat_05.csv', delimiter=',')\n",
    "\n",
    "print(f\"Input shape: {data_in.shape}\")\n",
    "print(f\"Output shape: {data_out.shape}\")\n",
    "\n",
    "# Handle outliers using Z-score (remove samples with |z| > 3)\n",
    "from scipy import stats\n",
    "\n",
    "z_scores_in = np.abs(stats.zscore(data_in))\n",
    "z_scores_out = np.abs(stats.zscore(data_out))\n",
    "\n",
    "mask_in = np.all(z_scores_in < 3, axis=1)\n",
    "mask_out = np.all(z_scores_out < 3, axis=1)\n",
    "mask = mask_in & mask_out\n",
    "\n",
    "data_in_clean = data_in[mask]\n",
    "data_out_clean = data_out[mask]\n",
    "\n",
    "print(f\"\\nAfter outlier removal (Z-score < 3):\")\n",
    "print(f\"  Input shape: {data_in_clean.shape}\")\n",
    "print(f\"  Output shape: {data_out_clean.shape}\")\n",
    "print(f\"  Samples removed: {data_in.shape[0] - data_in_clean.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a78f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NORMALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# MinMax scaling for inputs\n",
    "scaler_in = MinMaxScaler(feature_range=(-1, 1))\n",
    "U = scaler_in.fit_transform(data_in_clean)\n",
    "\n",
    "# Global max normalization for outputs (acceleration)\n",
    "global_max_abs_y = np.max(np.abs(data_out_clean))\n",
    "y_norm = data_out_clean / global_max_abs_y\n",
    "\n",
    "print(f\"Input normalization (MinMax):\")\n",
    "print(f\"  Original range: [{data_in_clean.min():.3f}, {data_in_clean.max():.3f}]\")\n",
    "print(f\"  Normalized range: [{U.min():.3f}, {U.max():.3f}]\")\n",
    "\n",
    "print(f\"\\nOutput normalization (global max):\")\n",
    "print(f\"  Original range: [{data_out_clean.min():.3f}, {data_out_clean.max():.3f}]\")\n",
    "print(f\"  Normalized range: [{y_norm.min():.3f}, {y_norm.max():.3f}]\")\n",
    "print(f\"  Global max value: {global_max_abs_y:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RESHAPING FOR SEQUENTIAL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# Create sequences (sliding window)\n",
    "seq_len = 20  # Context window\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "for i in range(len(U) - seq_len):\n",
    "    X_seq.append(U[i:i+seq_len])\n",
    "    y_seq.append(y_norm[i+seq_len])\n",
    "\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq).reshape(-1, 1)\n",
    "\n",
    "print(f\"Sequence creation:\")\n",
    "print(f\"  Sequence length: {seq_len}\")\n",
    "print(f\"  X_seq shape: {X_seq.shape}  (samples, timesteps, features)\")\n",
    "print(f\"  y_seq shape: {y_seq.shape}  (samples, 1)\")\n",
    "\n",
    "# Train-test split\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=test_size, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-test split ({(1-test_size)*100:.0f}% / {test_size*100:.0f}%):\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0eda7d",
   "metadata": {},
   "source": [
    "## 2. State Space Model Theory and Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0cfb6",
   "metadata": {},
   "source": [
    "### Continuous State Space Model\n",
    "\n",
    "A **state space model** describes a linear dynamical system using:\n",
    "\n",
    "$$\\dot{x}(t) = Ax(t) + Bu(t)$$\n",
    "$$y(t) = Cx(t) + Du(t)$$\n",
    "\n",
    "where:\n",
    "- $x(t) \\in \\mathbb{R}^n$ : state vector\n",
    "- $u(t) \\in \\mathbb{R}^m$ : control input\n",
    "- $y(t) \\in \\mathbb{R}^p$ : output (measurement)\n",
    "- $A \\in \\mathbb{R}^{n×n}$ : state transition matrix\n",
    "- $B \\in \\mathbb{R}^{n×m}$ : input matrix\n",
    "- $C \\in \\mathbb{R}^{p×n}$ : output matrix\n",
    "- $D \\in \\mathbb{R}^{p×m}$ : feedthrough matrix\n",
    "\n",
    "### Stability (Hurwitz Criterion)\n",
    "\n",
    "System is **stable** if all eigenvalues of $A$ have **negative real parts**: $\\text{Re}(\\lambda_i) < 0$ for all $i$.\n",
    "\n",
    "### Controllability and Observability\n",
    "\n",
    "**Controllability matrix:** $C = [B, AB, A^2B, ..., A^{n-1}B]$ must have full rank.\n",
    "\n",
    "**Observability matrix:** $O = [C^T, (CA)^T, (CA^2)^T, ..., (CA^{n-1})^T]^T$ must have full rank.\n",
    "\n",
    "### Recursive (RNN-like) View\n",
    "\n",
    "Iterate state sequentially:\n",
    "$$x_k = \\bar{A}x_{k-1} + \\bar{B}u_k$$\n",
    "$$y_k = \\bar{C}x_k$$\n",
    "\n",
    "**Memory efficient** (O(n²) per step), **inherently sequential**.\n",
    "\n",
    "### Convolutional (CNN-like) View\n",
    "\n",
    "Express output as convolution of input with kernel:\n",
    "$$y_k = \\sum_{j=0}^{k} K_j u_{k-j}$$\n",
    "\n",
    "where convolution kernel: $K_j = \\bar{C}\\bar{A}^j\\bar{B}$\n",
    "\n",
    "**Parallelizable** (O(L²) operations for sequence length L), great for **GPU training**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7a066",
   "metadata": {},
   "source": [
    "## 3. Discretization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249910cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISCRETIZATION METHODS\n",
    "# ============================================================================\n",
    "\n",
    "Ts = 0.05  # Sampling time\n",
    "\n",
    "def discretize_euler_forward(A, B, Ts):\n",
    "    \"\"\"Forward Euler discretization: x_{k+1} = (I + Ts*A) x_k + Ts*B u_k\n",
    "    Simple but less accurate, may cause stability issues.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    Ad = np.eye(n) + Ts * A\n",
    "    Bd = Ts * B\n",
    "    return Ad, Bd\n",
    "\n",
    "def discretize_euler_backward(A, B, Ts):\n",
    "    \"\"\"Backward (implicit) Euler: (I - Ts*A) x_{k+1} = x_k + Ts*B u_k\n",
    "    Stable but less accurate for fast dynamics.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    try:\n",
    "        Ad = np.linalg.inv(np.eye(n) - Ts * A)\n",
    "        Bd = Ad @ (Ts * B)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Backward Euler inversion failed, using forward Euler\")\n",
    "        Ad, Bd = discretize_euler_forward(A, B, Ts)\n",
    "    return Ad, Bd\n",
    "\n",
    "def discretize_bilinear(A, B, Ts):\n",
    "    \"\"\"Bilinear (trapezoid) discretization: preserves stability\n",
    "    Ā = (I - Ts/2·A)^(-1) (I + Ts/2·A)\n",
    "    B̄ = (I - Ts/2·A)^(-1) Ts·B\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    I = np.eye(n)\n",
    "    try:\n",
    "        left = I - (Ts / 2) * A\n",
    "        right = I + (Ts / 2) * A\n",
    "        Ad = np.linalg.solve(left, right)\n",
    "        Bd = np.linalg.solve(left, Ts * B)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Bilinear discretization failed\")\n",
    "        Ad, Bd = discretize_euler_forward(A, B, Ts)\n",
    "    return Ad, Bd\n",
    "\n",
    "print('✓ Discretization methods defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab43d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPARISON OF DISCRETIZATION METHODS\n",
    "# ============================================================================\n",
    "\n",
    "# Example continuous system\n",
    "A_cont = np.array([[-1.0, 1.0],\n",
    "                   [0.0, -2.0]])\n",
    "B_cont = np.array([[0.0],\n",
    "                   [1.0]])\n",
    "\n",
    "print(\"Continuous system:\")\n",
    "print(f\"A = \\n{A_cont}\")\n",
    "print(f\"B = \\n{B_cont}\")\n",
    "print(f\"Eigenvalues of A: {np.linalg.eigvals(A_cont)}\")\n",
    "print(f\"Stable: {np.all(np.real(np.linalg.eigvals(A_cont)) < 0)}\\n\")\n",
    "\n",
    "# Discretize using three methods\n",
    "Ad_euler, Bd_euler = discretize_euler_forward(A_cont, B_cont, Ts)\n",
    "Ad_backeuler, Bd_backeuler = discretize_euler_backward(A_cont, B_cont, Ts)\n",
    "Ad_bilinear, Bd_bilinear = discretize_bilinear(A_cont, B_cont, Ts)\n",
    "\n",
    "print(f\"Sampling time Ts = {Ts} s\\n\")\n",
    "print(\"Forward Euler:\")\n",
    "print(f\"  Ad eigenvalues: {np.linalg.eigvals(Ad_euler)}\")\n",
    "print(f\"  Magnitude: {np.abs(np.linalg.eigvals(Ad_euler))}\")\n",
    "print(f\"  Stable (|λ| < 1): {np.all(np.abs(np.linalg.eigvals(Ad_euler)) < 1)}\\n\")\n",
    "\n",
    "print(\"Backward Euler:\")\n",
    "print(f\"  Ad eigenvalues: {np.linalg.eigvals(Ad_backeuler)}\")\n",
    "print(f\"  Magnitude: {np.abs(np.linalg.eigvals(Ad_backeuler))}\")\n",
    "print(f\"  Stable (|λ| < 1): {np.all(np.abs(np.linalg.eigvals(Ad_backeuler)) < 1)}\\n\")\n",
    "\n",
    "print(\"Bilinear (Trapezoid):\")\n",
    "print(f\"  Ad eigenvalues: {np.linalg.eigvals(Ad_bilinear)}\")\n",
    "print(f\"  Magnitude: {np.abs(np.linalg.eigvals(Ad_bilinear))}\")\n",
    "print(f\"  Stable (|λ| < 1): {np.all(np.abs(np.linalg.eigvals(Ad_bilinear)) < 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c81cff",
   "metadata": {},
   "source": [
    "## 4. LQR Controller Design from First Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f728d",
   "metadata": {},
   "source": [
    "### Linear Quadratic Regulator (LQR)\n",
    "\n",
    "**Objective:** Find optimal control law $u^* = -Kx$ that minimizes:\n",
    "\n",
    "$$J = \\sum_{k=0}^{\\infty} (x_k^T Q x_k + u_k^T R u_k)$$\n",
    "\n",
    "where:\n",
    "- $Q \\in \\mathbb{R}^{n×n}$ : state cost (positive semidefinite)\n",
    "- $R \\in \\mathbb{R}^{m×m}$ : input cost (positive definite)\n",
    "\n",
    "**Solution via Discrete Algebraic Riccati Equation (DARE):**\n",
    "\n",
    "$$P = A^T P A - A^T P B (R + B^T P B)^{-1} B^T P A + Q$$\n",
    "\n",
    "**Optimal gain:**\n",
    "\n",
    "$$K = (R + B^T P B)^{-1} B^T P A$$\n",
    "\n",
    "**Interpretation:**\n",
    "- **Large Q values**: penalize state deviation (tight tracking)\n",
    "- **Large R values**: penalize control effort (smooth inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LQR DESIGN FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def lqr_design(Ad, Bd, Q, R):\n",
    "    \"\"\"Compute LQR gain K from discrete system and cost matrices.\n",
    "    \n",
    "    Solves Riccati equation: P = A'PA - A'PB(R + B'PB)^(-1)B'PA + Q\n",
    "    Optimal gain: K = (R + B'PB)^(-1)B'PA\n",
    "    \n",
    "    Returns:\n",
    "        K: optimal feedback gain (shape m×n)\n",
    "        P: solution to Riccati equation\n",
    "    \"\"\"\n",
    "    P = solve_discrete_are(Ad, Bd, Q, R)\n",
    "    K = np.linalg.inv(R + Bd.T @ P @ Bd) @ Bd.T @ P @ Ad\n",
    "    return K, P\n",
    "\n",
    "print('✓ LQR design function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE LQR DESIGN: 2×2 SYSTEM (position-velocity)\n",
    "# ============================================================================\n",
    "\n",
    "# Simple 2D system: x = [position, velocity]\n",
    "Ad_2x2 = np.array([[1.0, Ts],\n",
    "                   [0.0, 1.0]])\n",
    "Bd_2x2 = np.array([[0.0],\n",
    "                   [Ts]])\n",
    "\n",
    "print(\"2×2 System (position-velocity):\")\n",
    "print(f\"Ad = \\n{Ad_2x2}\")\n",
    "print(f\"Bd = \\n{Bd_2x2}\\n\")\n",
    "\n",
    "# Define cost matrices\n",
    "Q_2x2 = np.diag([100.0, 1.0])  # Heavy penalty on position error\n",
    "R_2x2 = np.array([[1.0]])       # Moderate control effort cost\n",
    "\n",
    "K_2x2, P_2x2 = lqr_design(Ad_2x2, Bd_2x2, Q_2x2, R_2x2)\n",
    "\n",
    "print(f\"LQR Gain K:\\n{K_2x2}\")\n",
    "print(f\"\\nRiccati solution P:\\n{P_2x2}\")\n",
    "print(f\"\\nClosed-loop eigenvalues (A - BK):\")\n",
    "A_cl = Ad_2x2 - Bd_2x2 @ K_2x2\n",
    "eigs_cl = np.linalg.eigvals(A_cl)\n",
    "print(f\"{eigs_cl}\")\n",
    "print(f\"Magnitude: {np.abs(eigs_cl)}\")\n",
    "print(f\"Stable: {np.all(np.abs(eigs_cl) < 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08060bc7",
   "metadata": {},
   "source": [
    "## 5. System Identification: Extracting A and B from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SYSTEM IDENTIFICATION VIA LEAST SQUARES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"System Identification: Extract 2×2 model from data\\n\")\n",
    "\n",
    "# Prepare identification data (use raw unnormalized for physical meaning)\n",
    "# Simplification: assume 2-state system [position, velocity]\n",
    "# and estimate from measured acceleration sequence\n",
    "\n",
    "# For demo: use the first 1000 samples\n",
    "n_id = min(1000, len(data_out_clean))\n",
    "a_measured = data_out_clean[:n_id, 0]  # Measured acceleration\n",
    "u_cmd = data_in_clean[:n_id, 0]        # Command input\n",
    "\n",
    "# Create state history by integrating acceleration\n",
    "v_hat = np.cumsum(a_measured) * Ts  # Velocity from integration\n",
    "z_hat = np.cumsum(v_hat) * Ts       # Position from integration\n",
    "\n",
    "# Prepare regression: stack state and input\n",
    "# x_k = [z_k, v_k], u_k = [a_k, u_cmd,k]\n",
    "# For simple model: a_{k+1} ≈ f(x_k) + gain*u_k\n",
    "\n",
    "# Simplified: model as x = [a_{k-1}, a_k] (acceleration history)\n",
    "# This is more practical given we only measure acceleration\n",
    "\n",
    "X_id = np.hstack([a_measured[:-1].reshape(-1, 1), u_cmd[:-1].reshape(-1, 1)])\n",
    "y_id = a_measured[1:].reshape(-1, 1)\n",
    "\n",
    "# Least squares: y = X * theta\n",
    "theta = np.linalg.lstsq(X_id, y_id, rcond=None)[0]\n",
    "\n",
    "print(f\"Regression model: a_{{k+1}} = θ_1 * a_k + θ_2 * u_k\")\n",
    "print(f\"Estimated parameters: θ = {theta.T}\")\n",
    "\n",
    "# Compute prediction and error\n",
    "y_pred = X_id @ theta\n",
    "rmse = np.sqrt(np.mean((y_pred - y_id)**2))\n",
    "mae = np.mean(np.abs(y_pred - y_id))\n",
    "\n",
    "print(f\"\\nModel performance:\")\n",
    "print(f\"  RMSE: {rmse:.6f}\")\n",
    "print(f\"  MAE: {mae:.6f}\")\n",
    "print(f\"  Variance explained: {(1 - np.var(y_pred - y_id) / np.var(y_id)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f2f548",
   "metadata": {},
   "source": [
    "## 6. SSM Implementation with Learnable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e956f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PYTORCH SSM LAYER WITH LEARNABLE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "class SSMLayer(nn.Module):\n",
    "    \"\"\"Learnable State Space Model layer.\n",
    "    \n",
    "    Continuous SSM: ẋ = Ax + Bu,  y = Cx\n",
    "    Discretized: x_k = Ā·x_{k-1} + B̄·u_k,  y_k = C̄·x_k\n",
    "    \n",
    "    Uses bilinear (trapezoid) discretization for numerical stability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim, input_dim, output_dim, dt=0.05):\n",
    "        super().__init__()\n",
    "        self.n = state_dim\n",
    "        self.m = input_dim\n",
    "        self.p = output_dim\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Learnable continuous matrices\n",
    "        self.A = nn.Parameter(torch.randn(state_dim, state_dim) * 0.1)\n",
    "        self.B = nn.Parameter(torch.randn(state_dim, input_dim) * 0.1)\n",
    "        self.C = nn.Parameter(torch.randn(output_dim, state_dim) * 0.1)\n",
    "        \n",
    "        # Initialize A to be stable (negative eigenvalues)\n",
    "        with torch.no_grad():\n",
    "            self.A.copy_(torch.randn(state_dim, state_dim) - 2 * torch.eye(state_dim))\n",
    "    \n",
    "    def discretize(self):\n",
    "        \"\"\"Discretize using bilinear (trapezoid) method with regularization.\n",
    "        \n",
    "        Returns:\n",
    "            A_bar, B_bar, C_bar: discretized matrices\n",
    "        \"\"\"\n",
    "        I = torch.eye(self.n, device=self.A.device, dtype=self.A.dtype)\n",
    "        \n",
    "        # Bilinear discretization\n",
    "        left_factor = I - (self.dt / 2) * self.A\n",
    "        right_factor = I + (self.dt / 2) * self.A\n",
    "        \n",
    "        # Add regularization for numerical stability\n",
    "        left_factor_reg = left_factor + 1e-6 * I\n",
    "        \n",
    "        # Solve via linear systems (more stable than explicit inversion)\n",
    "        A_bar = torch.linalg.solve(left_factor_reg, right_factor)\n",
    "        B_bar = torch.linalg.solve(left_factor_reg, self.dt * self.B)\n",
    "        C_bar = self.C\n",
    "        \n",
    "        return A_bar, B_bar, C_bar\n",
    "    \n",
    "    def forward_recursive(self, u_sequence):\n",
    "        \"\"\"Recursive forward pass (RNN-like, sequential).\n",
    "        \n",
    "        Args:\n",
    "            u_sequence: (batch, length, input_dim) tensor\n",
    "        \n",
    "        Returns:\n",
    "            y_sequence: (batch, length, output_dim) tensor\n",
    "        \"\"\"\n",
    "        batch_size, length, _ = u_sequence.shape\n",
    "        device = u_sequence.device\n",
    "        \n",
    "        A_bar, B_bar, C_bar = self.discretize()\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        x = torch.zeros(batch_size, self.n, device=device, dtype=u_sequence.dtype)\n",
    "        y_sequence = []\n",
    "        \n",
    "        for k in range(length):\n",
    "            # x_k = Ā·x_{k-1} + B̄·u_k  (batch-friendly form)\n",
    "            u_k = u_sequence[:, k, :].reshape(batch_size, self.m)\n",
    "            x = x @ A_bar.T + u_k @ B_bar.T\n",
    "            \n",
    "            # y_k = C̄·x_k\n",
    "            y = x @ C_bar.T\n",
    "            y_sequence.append(y)\n",
    "        \n",
    "        y_sequence = torch.stack(y_sequence, dim=1)  # (batch, length, output_dim)\n",
    "        return y_sequence\n",
    "    \n",
    "    def forward(self, u_sequence):\n",
    "        \"\"\"Default forward pass (recursive view).\"\"\"\n",
    "        return self.forward_recursive(u_sequence)\n",
    "\n",
    "print('✓ SSMLayer class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c92b2e",
   "metadata": {},
   "source": [
    "## 7. Training SSM as Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SSM TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize SSM model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "state_dim = 8\n",
    "ssm_model = SSMLayer(state_dim=state_dim, input_dim=1, output_dim=1, dt=Ts).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ssm_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING SSM MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"State dimension: {state_dim}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "\n",
    "# Training loop\n",
    "ssm_train_losses = []\n",
    "ssm_val_losses = []\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = ssm_model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    ssm_train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        val_output = ssm_model(X_test_tensor.to(device))\n",
    "        val_loss = criterion(val_output, y_test_tensor.to(device))\n",
    "        ssm_val_losses.append(val_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss.item():.6f}\")\n",
    "\n",
    "print(f\"\\n✓ SSM training complete\")\n",
    "print(f\"  Final train loss: {ssm_train_losses[-1]:.6f}\")\n",
    "print(f\"  Final val loss: {ssm_val_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62330f42",
   "metadata": {},
   "source": [
    "## 8. LQI with Kalman Observer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0167520",
   "metadata": {},
   "source": [
    "### LQI (Linear Quadratic Integrator)\n",
    "\n",
    "**Problem:** Standard LQR requires full state knowledge. If only acceleration is measured:\n",
    "- Need observer to estimate unmeasured states (position, velocity)\n",
    "- Add integrator state η to reject steady-state errors and bias\n",
    "\n",
    "**Augmented State:** χ = [x; v; z; η]\n",
    "- x: system states (latents)\n",
    "- v: velocity (from integrating acceleration)\n",
    "- z: position (from integrating velocity)\n",
    "- η: integrator state (η_{k+1} = η_k + e_k where e_k = z_k - r_k)\n",
    "\n",
    "**Control Law:** u = -K·χ̂\n",
    "\n",
    "**Kalman Observer:** Estimates χ̂ from noisy acceleration measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LQI SYSTEM CONSTRUCTION\n",
    "# ============================================================================\n",
    "\n",
    "def build_lqi_system_2x2(Ad, Bd, C, D, b, Ts):\n",
    "    \"\"\"Build augmented LQI system from 2×2 identified model.\n",
    "    \n",
    "    Returns:\n",
    "        A_lqi (5,5): augmented system matrix\n",
    "        B_lqi (5,1): augmented input matrix\n",
    "        C_meas (1,5): measurement matrix (acceleration)\n",
    "        D_meas (1,1): measurement feedthrough\n",
    "    \"\"\"\n",
    "    n = Ad.shape[0]  # 2\n",
    "    \n",
    "    # Augmented system: [x; a; z; eta]\n",
    "    # Dynamics: x_{k+1} = Ad x_k + Bd u_k\n",
    "    #           a_{k+1} = C x_k + D u_k + b\n",
    "    #           z_{k+1} = z_k + Ts * a_k\n",
    "    #           eta_{k+1} = eta_k + (z_k - r_k)\n",
    "    \n",
    "    A_lqi = np.block([\n",
    "        [Ad,            np.zeros((2,1)),  np.zeros((2,1)), np.zeros((2,1))],\n",
    "        [C.reshape(1,2), np.zeros((1,1)),  np.zeros((1,1)), np.zeros((1,1))],\n",
    "        [np.zeros((1,2)), np.array([[Ts]]),  np.array([[1.0]]), np.zeros((1,1))],\n",
    "        [np.zeros((1,2)), np.zeros((1,1)),  np.array([[1.0]]), np.array([[1.0]])]\n",
    "    ])\n",
    "    \n",
    "    B_lqi = np.vstack([Bd.reshape(2,1), D.reshape(1,1), np.array([[0.0]]), np.array([[0.0]])])\n",
    "    \n",
    "    # Measurement: observe acceleration only\n",
    "    C_meas = np.hstack([C.reshape(1,2), np.array([[1.0]]), np.zeros((1,2))])\n",
    "    D_meas = np.array([[0.0]])\n",
    "    \n",
    "    return A_lqi, B_lqi, C_meas, D_meas\n",
    "\n",
    "print('✓ LQI system builder defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KALMAN FILTER DESIGN\n",
    "# ============================================================================\n",
    "\n",
    "def kalman_gain_discrete(A, C, Qn, Rn):\n",
    "    \"\"\"Compute Kalman filter gain L via discrete ARE.\n",
    "    \n",
    "    Args:\n",
    "        A: (n,n) state matrix\n",
    "        C: (p,n) measurement matrix\n",
    "        Qn: (n,n) process noise covariance\n",
    "        Rn: (p,p) measurement noise covariance\n",
    "    \n",
    "    Returns:\n",
    "        L: (n,p) Kalman gain\n",
    "    \"\"\"\n",
    "    # Solve ARE for observer\n",
    "    P = solve_discrete_are(A.T, C.T, Qn, Rn)\n",
    "    L = (P @ C.T) @ np.linalg.inv(C @ P @ C.T + Rn)\n",
    "    return L\n",
    "\n",
    "# Example: compute gains for 2×2 system\n",
    "Ad_identified = np.array([[1.0, Ts], [0.0, 0.95]])  # Example identified system\n",
    "Bd_identified = np.array([[0.0], [Ts]])\n",
    "C_identified = np.array([[0.0, 1.0]])\n",
    "D_identified = np.array([[1.0]])\n",
    "b_identified = 0.0\n",
    "\n",
    "# Build LQI system\n",
    "A_lqi, B_lqi, C_meas, D_meas = build_lqi_system_2x2(\n",
    "    Ad_identified, Bd_identified, C_identified, D_identified, b_identified, Ts\n",
    ")\n",
    "\n",
    "print(f\"Augmented LQI system shape: A_lqi = {A_lqi.shape}\")\n",
    "\n",
    "# LQI gains\n",
    "Q_lqi = np.diag([1e-2, 1e-2, 100.0, 1000.0])  # [x, a, z, eta]\n",
    "R_lqi = np.array([[0.1]])\n",
    "\n",
    "K_lqi, P_lqi = lqr_design(A_lqi, B_lqi, Q_lqi, R_lqi)\n",
    "\n",
    "print(f\"LQI Gain K shape: {K_lqi.shape}\")\n",
    "print(f\"LQI Gain K: {K_lqi}\")\n",
    "\n",
    "# Kalman observer gains\n",
    "Qn_kalman = 1e-5 * np.eye(4)  # Process noise\n",
    "Rn_kalman = np.array([[1e-2]])  # Measurement noise (acceleration)\n",
    "\n",
    "L_kalman = kalman_gain_discrete(A_lqi, C_meas, Qn_kalman, Rn_kalman)\n",
    "\n",
    "print(f\"\\nKalman Observer Gain L shape: {L_kalman.shape}\")\n",
    "print(f\"Kalman Gain L: {L_kalman.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe53908",
   "metadata": {},
   "source": [
    "## 9. LQR Closed-Loop Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LQR CLOSED-LOOP SIMULATION\n",
    "# ============================================================================\n",
    "\n",
    "def simulate_lqr(Ad, Bd, C, D, b, K, initial_state, target_height, num_steps, dt=0.05, max_cmd=1.0):\n",
    "    \"\"\"Simulate LQR closed-loop control.\n",
    "    \n",
    "    Control law: u_k = -K(x_k - x_target)\n",
    "    \"\"\"\n",
    "    positions = [initial_state[0]]\n",
    "    velocities = [initial_state[1]]\n",
    "    accelerations = []\n",
    "    commands = []\n",
    "    \n",
    "    x = initial_state.copy()\n",
    "    \n",
    "    for k in range(num_steps):\n",
    "        # Error: position vs target\n",
    "        pos_error = positions[-1] - target_height\n",
    "        \n",
    "        # LQR control: u = -K @ [pos_error, vel]\n",
    "        state_error = np.array([pos_error, velocities[-1]])\n",
    "        u = -K @ state_error.reshape(-1, 1)\n",
    "        u = float(np.clip(u, -max_cmd, max_cmd))\n",
    "        commands.append(u)\n",
    "        \n",
    "        # State update\n",
    "        x = Ad @ x.reshape(-1, 1) + Bd * np.array([[u]])\n",
    "        x = x.flatten()\n",
    "        \n",
    "        # Measurement\n",
    "        a = (C @ x.reshape(-1, 1) + D * np.array([[u]]) + b).item()\n",
    "        accelerations.append(a)\n",
    "        \n",
    "        # Integration for next step\n",
    "        positions.append(positions[-1] + velocities[-1] * dt)\n",
    "        velocities.append(velocities[-1] + a * dt)\n",
    "    \n",
    "    return (np.array(positions), np.array(velocities), np.array(accelerations),\n",
    "            np.array(commands))\n",
    "\n",
    "# Run simulation\n",
    "pos_lqr, vel_lqr, acc_lqr, cmd_lqr = simulate_lqr(\n",
    "    Ad_identified, Bd_identified, C_identified, D_identified, b_identified,\n",
    "    K_2x2,  # Use simple 2×2 LQR gain\n",
    "    initial_state=np.array([0.0, 0.0]),\n",
    "    target_height=10.0,\n",
    "    num_steps=300\n",
    ")\n",
    "\n",
    "print(f\"✓ LQR simulation complete\")\n",
    "print(f\"  Final position: {pos_lqr[-1]:.3f} m (target: 10.0 m)\")\n",
    "print(f\"  Final velocity: {vel_lqr[-1]:.3f} m/s\")\n",
    "print(f\"  Control effort (sum |u|): {np.sum(np.abs(cmd_lqr)):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a9975",
   "metadata": {},
   "source": [
    "## 10. Performance Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeead83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PERFORMANCE METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_performance_metrics(positions, velocities, accelerations, commands, target_height, dt=0.05):\n",
    "    \"\"\"Compute control performance metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Position error\n",
    "    pos_error = positions - target_height\n",
    "    metrics['mean_pos_error'] = np.mean(np.abs(pos_error[-50:]))  # Steady-state\n",
    "    metrics['final_pos_error'] = np.abs(pos_error[-1])\n",
    "    metrics['max_pos_error'] = np.max(np.abs(pos_error))\n",
    "    \n",
    "    # Rise time (time to reach 90% of target)\n",
    "    idx_90 = np.argmax(positions >= 0.9 * target_height)\n",
    "    metrics['rise_time'] = idx_90 * dt if idx_90 > 0 else np.nan\n",
    "    \n",
    "    # Overshoot\n",
    "    max_pos = np.max(positions)\n",
    "    metrics['overshoot_pct'] = max((max_pos - target_height) / target_height * 100, 0)\n",
    "    \n",
    "    # Settling time (within 2% of target for 10 consecutive samples)\n",
    "    idx_settled = np.where(np.abs(pos_error) <= 0.02 * target_height)[0]\n",
    "    if len(idx_settled) >= 10:\n",
    "        metrics['settling_time'] = idx_settled[0] * dt\n",
    "    else:\n",
    "        metrics['settling_time'] = np.nan\n",
    "    \n",
    "    # Control effort and smoothness\n",
    "    metrics['control_effort'] = np.sum(np.abs(commands))\n",
    "    metrics['control_smoothness'] = np.std(np.diff(commands))\n",
    "    \n",
    "    # Final velocity error\n",
    "    metrics['final_vel_error'] = np.abs(velocities[-1])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics_lqr = compute_performance_metrics(pos_lqr, vel_lqr, acc_lqr, cmd_lqr, 10.0)\n",
    "\n",
    "print(\"LQR Performance Metrics:\")\n",
    "for key, val in metrics_lqr.items():\n",
    "    print(f\"  {key}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "t = np.arange(len(pos_lqr)) * Ts\n",
    "target = 10.0\n",
    "\n",
    "# Position tracking\n",
    "axes[0, 0].plot(t, pos_lqr, 'b-', linewidth=2, label='Position')\n",
    "axes[0, 0].axhline(target, color='k', linestyle='--', alpha=0.5, label='Target')\n",
    "axes[0, 0].fill_between(t, target - 0.2, target + 0.2, alpha=0.1, color='gray')\n",
    "axes[0, 0].set_ylabel('Position (m)')\n",
    "axes[0, 0].set_title('LQR Position Tracking')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Position error\n",
    "error = pos_lqr - target\n",
    "axes[0, 1].plot(t, error, 'r-', linewidth=1.5)\n",
    "axes[0, 1].axhline(0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[0, 1].fill_between(t, -0.2, 0.2, alpha=0.1, color='gray')\n",
    "axes[0, 1].set_ylabel('Position Error (m)')\n",
    "axes[0, 1].set_title('Position Error vs Target')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Velocity\n",
    "axes[1, 0].plot(t, vel_lqr, 'g-', linewidth=2)\n",
    "axes[1, 0].set_ylabel('Velocity (m/s)')\n",
    "axes[1, 0].set_title('Velocity Profile')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Acceleration\n",
    "axes[1, 1].plot(t, acc_lqr, 'orange', linewidth=1.5)\n",
    "axes[1, 1].set_ylabel('Acceleration (m/s²)')\n",
    "axes[1, 1].set_title('Acceleration from System')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Control command\n",
    "axes[2, 0].plot(t[:-1], cmd_lqr, 'purple', linewidth=1.5)\n",
    "axes[2, 0].set_ylabel('Command')\n",
    "axes[2, 0].set_xlabel('Time (s)')\n",
    "axes[2, 0].set_title('LQR Control Command')\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Phase portrait\n",
    "axes[2, 1].plot(pos_lqr, vel_lqr, 'b-', linewidth=2, label='Trajectory')\n",
    "axes[2, 1].plot(pos_lqr[0], vel_lqr[0], 'go', markersize=10, label='Start')\n",
    "axes[2, 1].plot(pos_lqr[-1], vel_lqr[-1], 'r*', markersize=15, label='End')\n",
    "axes[2, 1].axvline(target, color='k', linestyle='--', alpha=0.5, label='Target')\n",
    "axes[2, 1].set_xlabel('Position (m)')\n",
    "axes[2, 1].set_ylabel('Velocity (m/s)')\n",
    "axes[2, 1].set_title('Phase Portrait (Pos vs Vel)')\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('LQR Control Simulation Results', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lqr_simulation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('✓ Visualization saved as lqr_simulation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pour control_law.py\n",
    "ssm_export = {\n",
    "    'A': ssm_model.A.detach().cpu().numpy(),\n",
    "    'B': ssm_model.B.detach().cpu().numpy(),\n",
    "    'C': ssm_model.C.detach().cpu().numpy(),\n",
    "    'Ts': 0.05\n",
    "}\n",
    "np.savez('ssm_matrices.npz', **ssm_export)\n",
    "print(\"✓ Matrices exportées dans ssm_matrices.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5969ce",
   "metadata": {},
   "source": [
    "## 11. Summary and Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed5dab",
   "metadata": {},
   "source": [
    "### Key Concepts Covered\n",
    "\n",
    "1. **State Space Models (SSM)**\n",
    "   - Continuous formulation: ẋ = Ax + Bu, y = Cx\n",
    "   - Three discretization methods: Euler forward/backward, Bilinear\n",
    "   - Two computational views: Recursive (RNN-like), Convolutional (CNN-like)\n",
    "   - Learnable SSM with neural networks\n",
    "\n",
    "2. **Linear Quadratic Regulator (LQR)**\n",
    "   - Optimal feedback control via Riccati equation\n",
    "   - Cost function: J = Σ(x'Qx + u'Ru)\n",
    "   - Gain K computed from DARE solution\n",
    "   - Trade-off between state accuracy and control effort\n",
    "\n",
    "3. **System Identification**\n",
    "   - Extract physical 2×2 model (position-velocity) from data\n",
    "   - Least squares regression from acceleration measurements\n",
    "   - Validate model against test data\n",
    "\n",
    "4. **LQI with Kalman Observer**\n",
    "   - Augmented state includes integrator for bias rejection\n",
    "   - Observer estimates full state from acceleration measurement alone\n",
    "   - Discrete Kalman filter gain computation\n",
    "\n",
    "5. **Performance Evaluation**\n",
    "   - Metrics: rise time, settling time, overshoot, steady-state error\n",
    "   - Control effort and smoothness assessment\n",
    "   - Phase portrait analysis\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "- **Drone altitude control** with IMU (acceleration) feedback\n",
    "- **Position tracking** under model uncertainty\n",
    "- **Hybrid control** combining classical LQR with neural learning\n",
    "- **Real-time inference** using recursive SSM view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a6faa",
   "metadata": {},
   "source": [
    "## 12. Understanding Latent Space: SSM Learning vs Physical System Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977b63c",
   "metadata": {},
   "source": [
    "### The Fundamental Difference\n",
    "\n",
    "**System Identification (Physical Model):**\n",
    "- Extract A, B from **known physical structure**: x = [position, velocity]\n",
    "- Use least-squares: direct computation, one pass\n",
    "- Result: **interpretable matrices** (you know what each state means)\n",
    "- Limitation: assumes linear system\n",
    "\n",
    "**SSM Training (Neural Latent Space):**\n",
    "- Learn A, B via **gradient descent** on random initialization\n",
    "- Optimize matrices to **minimize prediction error**\n",
    "- Result: **opaque latent representations** (8 dimensions that capture patterns)\n",
    "- Advantage: can model nonlinearities, complex dynamics\n",
    "\n",
    "### Analogy: Data Compression\n",
    "\n",
    "```\n",
    "Physical System ID:     1000 input features → force to 2 states (z, v)\n",
    "                                              → lose lots of info ❌\n",
    "\n",
    "SSM Training:           1000 input features → auto-learn 8 latent dimensions\n",
    "                                              → compress intelligently ✅\n",
    "```\n",
    "\n",
    "The SSM learns a **low-dimensional manifold** that best predicts output.\n",
    "It's like **Principal Component Analysis (PCA)**, but with dynamics and nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZING LATENT SPACE: What does SSM learn?\n",
    "# ============================================================================\n",
    "\n",
    "# Extract learned A, B, C matrices\n",
    "with torch.no_grad():\n",
    "    A_learned_disc, B_learned_disc, C_learned_disc = ssm_model.discretize()\n",
    "    A_learned = ssm_model.A.cpu().numpy()\n",
    "    B_learned = ssm_model.B.cpu().numpy()\n",
    "    C_learned = ssm_model.C.cpu().numpy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LEARNED SSM MATRICES (8-dimensional latent space)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nA matrix shape: {A_learned.shape} (continuous)\")\n",
    "print(f\"A eigenvalues: {np.linalg.eigvals(A_learned)}\")\n",
    "print(f\"Discrete A eigenvalues magnitude: {np.abs(np.linalg.eigvals(A_learned_disc.cpu().numpy()))}\")\n",
    "\n",
    "print(f\"\\nB matrix shape: {B_learned.shape}\")\n",
    "print(f\"B (input coupling to latent states):\\n{B_learned.flatten()[:5]}... (showing first 5)\")\n",
    "\n",
    "print(f\"\\nC matrix shape: {C_learned.shape}\")\n",
    "print(f\"C (output from latent states): {C_learned.flatten()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Each dimension in the 8-dimensional latent space captures:\n",
    "  - Dimension 0: might capture 'velocity-like' behavior\n",
    "  - Dimension 1: might capture 'inertia' or 'integration' \n",
    "  - Dimension 2-7: complex combinations, higher-order dynamics\n",
    "  \n",
    "But we DON'T know explicitly ! The network learned optimal combinations\n",
    "to minimize |y_pred - y_true|.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50309543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPARISON: System ID vs SSM Learning\n",
    "# ============================================================================\n",
    "\n",
    "comparison_data = {\n",
    "    'Aspect': [\n",
    "        'Dimensions',\n",
    "        'Derivation',\n",
    "        'Computation',\n",
    "        'Interpretability',\n",
    "        'Flexibility',\n",
    "        'Guarantees',\n",
    "        'Time to compute',\n",
    "        'Use case'\n",
    "    ],\n",
    "    'System ID (2×2 Physical)': [\n",
    "        'n=2 (z, v)',\n",
    "        'From physics equations',\n",
    "        'Least-squares (one pass)',\n",
    "        '✓ Full (you know z, v)',\n",
    "        '✗ Fixed structure',\n",
    "        '✓ Controllable/observable',\n",
    "        'seconds',\n",
    "        'LQR/LQI design, control'\n",
    "    ],\n",
    "    'SSM Learning (8×8 Latent)': [\n",
    "        'n=8 (abstract)',\n",
    "        'From data via gradient',\n",
    "        'Gradient descent (iterative)',\n",
    "        '✗ Opaque (what is dim 3?)',\n",
    "        '✓ Flexible patterns',\n",
    "        '✗ No guarantees',\n",
    "        'minutes',\n",
    "        'Prediction, anomaly detection'\n",
    "    ]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUAL ANALOGY:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "SYSTEM ID:                    SSM TRAINING:\n",
    "─────────────────────────────────────────────────────────\n",
    "   Signal                        Signal\n",
    "     │                             │\n",
    "     ↓ Extract structure            ↓ Compress intelligently\n",
    "  (z, v)  ← 2D, physical         (z₁...z₈) ← 8D, latent\n",
    "     │                             │\n",
    "     ↓ Use for control             ↓ Use for prediction\n",
    "  Design LQR/LQI              Neural network model\n",
    "     \n",
    "  Transparency: 100%           Transparency: 20%\n",
    "  Control: ✓✓✓               Prediction: ✓✓\n",
    "  Physics: ✓✓✓               Physics: ✗\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEEP DIVE: How SSM creates latent space\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HOW DOES SSM CREATE LATENT SPACE FROM DATA?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "STEP 1: Initialize Randomly\n",
    "──────────────────────────\n",
    "A_0 = random 8×8 matrix  ← NO STRUCTURE\n",
    "B_0 = random 8×1 matrix\n",
    "C_0 = random 1×8 matrix\n",
    "\n",
    "This is like a blank slate !\n",
    "\n",
    "\n",
    "STEP 2: Forward Pass (Batch of sequences)\n",
    "──────────────────────────────────────────\n",
    "For sequence u = [u_0, u_1, ..., u_20]:\n",
    "  x_0 = 0  (initial hidden state)\n",
    "  x_1 = A_0·x_0 + B_0·u_0\n",
    "  x_2 = A_0·x_1 + B_0·u_1\n",
    "  ...\n",
    "  x_20 = A_0·x_19 + B_0·u_19\n",
    "  \n",
    "  y_pred = [C_0·x_1, C_0·x_2, ..., C_0·x_20]\n",
    "\n",
    "This predicts the acceleration sequence.\n",
    "\n",
    "\n",
    "STEP 3: Compute Loss\n",
    "──────────────────\n",
    "loss = ||y_pred - y_true||²\n",
    "\n",
    "For 1000 samples in a batch:\n",
    "  loss = Σ(y_pred_i - y_true_i)²\n",
    "\n",
    "How bad is our prediction?\n",
    "\n",
    "\n",
    "STEP 4: Backpropagation\n",
    "──────────────────────\n",
    "Compute gradients:\n",
    "  ∂loss/∂A, ∂loss/∂B, ∂loss/∂C\n",
    "\n",
    "These gradients point in the direction to reduce loss !\n",
    "\n",
    "\n",
    "STEP 5: Update (Gradient Descent)\n",
    "────────────────────────────────\n",
    "A = A - η·(∂loss/∂A)\n",
    "B = B - η·(∂loss/∂B)  \n",
    "C = C - η·(∂loss/∂C)\n",
    "\n",
    "Now A, B, C are SLIGHTLY better at predicting.\n",
    "\n",
    "\n",
    "REPEAT 30 times (epochs)\n",
    "────────────────────────\n",
    "After 30 epochs:\n",
    "  - A captures \"how hidden states evolve\"\n",
    "  - B captures \"how input affects hidden states\"\n",
    "  - C captures \"how hidden states become output\"\n",
    "  \n",
    "BUT each of the 8 dimensions is a LEARNED ABSTRACTION.\n",
    "It's NOT z, NOT v, but rather optimal combinations.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALOGY: Dimensionality Reduction\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Think of your data like a 1000-D point cloud.\n",
    "\n",
    "PCA would find 2 principal axes (greatest variance).\n",
    "SSM with latent space finds 8 dimensions that best PREDICT future outputs.\n",
    "\n",
    "It's like:\n",
    "  Input u → enters 8-D latent manifold → evolves by matrix A\n",
    "           → projects onto output y via matrix C\n",
    "\n",
    "The network found the BEST 8-D compression for prediction.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nKey insight: The 8 latent dimensions are DATA-DRIVEN, not physics-driven!\")\n",
    "print(\"              They're whatever the loss function pressures them to be.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0737c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRACTICAL IMPLICATION: Can we use SSM latent space for control?\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FOR YOUR DRONE CONTROL PROBLEM:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "❌ WRONG APPROACH: Use learned SSM matrices for LQR\n",
    "───────────────────────────────────────────────────\n",
    "ssm_8d_A = ssm_model.A  # 8×8 learned matrix\n",
    "K_from_ssm = lqr_design(ssm_8d_A, ssm_8d_B, Q, R)[0]\n",
    "\n",
    "Problem: The 8 latent dimensions DON'T correspond to:\n",
    "  - Position (can't track altitude explicitly)\n",
    "  - Velocity (no meaningful velocity interpretation)\n",
    "  - State constraints (can't penalize max velocity safely)\n",
    "  \n",
    "The LQR gain would try to regulate 8 abstract dimensions!\n",
    "You can't physically interpret what u = -K @ x_latent means.\n",
    "\n",
    "\n",
    "✓ RIGHT APPROACH: Use physical model + SSM for hybrid control\n",
    "──────────────────────────────────────────────────────────────\n",
    "1. Extract A_physical, B_physical (2×2) via system ID\n",
    "   └─ Use for: LQR design, safety constraints, Kalman observer\n",
    "\n",
    "2. Train SSM_8d with latent space\n",
    "   └─ Use for: forward prediction, model mismatch correction\n",
    "   \n",
    "3. Hybrid control law:\n",
    "   u = u_LQR(z, v) + α·u_correction(e_prediction)\n",
    "   \n",
    "   Where:\n",
    "   - u_LQR : physically meaningful (regulates z, v)\n",
    "   - u_correction : fixes model errors (learned by SSM)\n",
    "   - α : blending factor (tune for your system)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"  • System ID (2×2) → interpretable, safe, control-ready ✓\")\n",
    "print(\"  • SSM (8×8) → flexible, predictive, not for direct control ✗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abfce8",
   "metadata": {},
   "source": [
    "## 13. Hidden State x: What Is It and How to Use It?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052a5bc",
   "metadata": {},
   "source": [
    "### Understanding x (Hidden State)\n",
    "\n",
    "**The Critical Question:** *\"What is x? Is it my input data?\"*\n",
    "\n",
    "**Answer:** NO! x is an **internal hidden state** that:\n",
    "- Is NOT directly observed\n",
    "- Evolves dynamically: $x_{k+1} = A \\cdot x_k + B \\cdot u_k$\n",
    "- Compresses all past history into a fixed-size vector\n",
    "- Allows SSM to have \"memory\" without storing full history\n",
    "\n",
    "### Visualization: Data vs Hidden State\n",
    "\n",
    "```\n",
    "YOUR ACTUAL DATA (u, y):\n",
    "═══════════════════════════════════════════════════════════\n",
    "Time:   0    1    2    3    4    5   ...  100\n",
    "u:    [0.5, 0.3, 0.8, 0.1, 0.9, 0.2, ..., 0.6]  ← Measured input\n",
    "y:    [0.1, 0.2, 0.3, 0.5, 0.7, 1.1, ..., 5.2]  ← Measured output\n",
    "\n",
    "\n",
    "HIDDEN STATE x (what SSM creates):\n",
    "═══════════════════════════════════════════════════════════\n",
    "Time:   0      1      2      3      4      5   ...  100\n",
    "x:   [0...0] [?,?,?,?,?,?,?,?] [?,?,?,?,?,?,?,?] ... [?,?,?,?,?,?,?,?]\n",
    "     (8-D)      (8-D)                                   (8-D)\n",
    "     \n",
    "Each dimension is a learned feature, evolving according to A matrix.\n",
    "```\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "The hidden state x is like the **\"memory\" of an RNN**:\n",
    "- It's initialized to zero: $x_0 = \\mathbf{0}$\n",
    "- It absorbs all information from past inputs\n",
    "- At each step, it's updated and used to predict output\n",
    "- After 100 steps, x contains compressed information about all 100 past inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 1: Manual SSM forward pass (understanding x evolution)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE: Manual SSM Forward Pass\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Simplified 2D system for visualization (instead of 8D)\n",
    "state_dim_demo = 2\n",
    "A_demo = np.array([[0.9, 0.1],\n",
    "                   [0.0, 0.8]])  # Each step, x slightly decays\n",
    "B_demo = np.array([[1.0],\n",
    "                   [2.0]])       # Input affects both state dims\n",
    "C_demo = np.array([[0.5, 0.3]])  # Output is weighted sum of states\n",
    "\n",
    "print(f\"\\nA matrix (state evolution):\\n{A_demo}\")\n",
    "print(f\"\\nB matrix (input coupling):\\n{B_demo}\")\n",
    "print(f\"\\nC matrix (output from state):\\n{C_demo}\")\n",
    "\n",
    "# Simulate\n",
    "u_sequence = np.array([1.0, 0.5, 0.8, 0.2, 0.0])  # Input sequence\n",
    "num_steps = len(u_sequence)\n",
    "\n",
    "# Initialize hidden state to ZERO\n",
    "x = np.zeros((state_dim_demo, 1))\n",
    "print(f\"\\nInitial hidden state x_0:\\n{x.T}\")\n",
    "\n",
    "# Store trajectory\n",
    "x_trajectory = [x.copy()]\n",
    "y_trajectory = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"STEP-BY-STEP EVOLUTION:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for k, u_k in enumerate(u_sequence):\n",
    "    # Predict output from CURRENT state\n",
    "    y_k = C_demo @ x\n",
    "    y_trajectory.append(float(y_k))\n",
    "    \n",
    "    # Update hidden state for NEXT step\n",
    "    x = A_demo @ x + B_demo * u_k\n",
    "    x_trajectory.append(x.copy())\n",
    "    \n",
    "    print(f\"\\nStep {k}:\")\n",
    "    print(f\"  Input u_{k} = {u_k:.1f}\")\n",
    "    print(f\"  Output y_{k} = C @ x_{k} = {y_k[0,0]:.4f}\")\n",
    "    print(f\"  Next state x_{k+1} = A @ x_{k} + B @ u_{k}:\")\n",
    "    print(f\"    x_{k+1} = {x.T[0]}\")\n",
    "\n",
    "# Convert to arrays for visualization\n",
    "x_trajectory = np.array([x.flatten() for x in x_trajectory])\n",
    "y_trajectory = np.array(y_trajectory)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInput sequence u:      {u_sequence}\")\n",
    "print(f\"Output sequence y:     {y_trajectory}\")\n",
    "print(f\"\\nHidden state trajectory (dim 0):\\n{x_trajectory[:, 0]}\")\n",
    "print(f\"Hidden state trajectory (dim 1):\\n{x_trajectory[:, 1]}\")\n",
    "\n",
    "print(\"\\n✓ Key observation:\")\n",
    "print(\"  - x_0 = [0, 0] (starts empty)\")\n",
    "print(\"  - x evolves with each step\")\n",
    "print(\"  - x accumulates information from all past inputs\")\n",
    "print(\"  - y depends on x (not directly on u!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 2: Generate complete trajectory from SSM model\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING COMPLETE TRAJECTORY WITH SSM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def ssm_trajectory(A, B, C, u_sequence, x_init=None):\n",
    "    \"\"\"Generate full trajectory from SSM given input sequence.\n",
    "    \n",
    "    Args:\n",
    "        A: state matrix (n×n)\n",
    "        B: input matrix (n×m)\n",
    "        C: output matrix (p×n)\n",
    "        u_sequence: input sequence (T,) or (T, m)\n",
    "        x_init: initial hidden state (n,) or None (default: zero)\n",
    "    \n",
    "    Returns:\n",
    "        y_trajectory: output trajectory (T,)\n",
    "        x_trajectory: hidden state trajectory (T, n)\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    T = len(u_sequence)\n",
    "    \n",
    "    # Initialize\n",
    "    if x_init is None:\n",
    "        x = np.zeros(n)\n",
    "    else:\n",
    "        x = x_init.copy()\n",
    "    \n",
    "    x_traj = np.zeros((T+1, n))\n",
    "    y_traj = np.zeros(T)\n",
    "    \n",
    "    x_traj[0] = x\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Current output\n",
    "        y_traj[t] = C @ x\n",
    "        \n",
    "        # Update state for next step\n",
    "        u_t = u_sequence[t] if np.isscalar(u_sequence[t]) else u_sequence[t, 0]\n",
    "        x = A @ x + B.flatten() * u_t\n",
    "        x_traj[t+1] = x\n",
    "    \n",
    "    return y_traj, x_traj\n",
    "\n",
    "# Use our demo system\n",
    "u_input = np.sin(np.linspace(0, 4*np.pi, 100)) * 0.5  # Sinusoidal input\n",
    "y_pred, x_traj = ssm_trajectory(A_demo, B_demo, C_demo, u_input)\n",
    "\n",
    "print(f\"\\nInput signal: sinusoid, 100 samples\")\n",
    "print(f\"Output trajectory shape: {y_pred.shape}\")\n",
    "print(f\"Hidden state trajectory shape: {x_traj.shape}\")\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "# Input\n",
    "axes[0].plot(u_input, 'b-', linewidth=2, label='Input u')\n",
    "axes[0].set_ylabel('Input u')\n",
    "axes[0].set_title('Input Signal')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Output\n",
    "axes[1].plot(y_pred, 'r-', linewidth=2, label='Output y')\n",
    "axes[1].set_ylabel('Output y')\n",
    "axes[1].set_title('System Output (from SSM)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "# Hidden states\n",
    "axes[2].plot(x_traj[:, 0], 'g-', linewidth=2, label='x[0] (hidden dim 0)')\n",
    "axes[2].plot(x_traj[:, 1], 'purple', linewidth=2, label='x[1] (hidden dim 1)')\n",
    "axes[2].set_ylabel('Hidden State')\n",
    "axes[2].set_xlabel('Time step')\n",
    "axes[2].set_title('Evolution of Hidden States x')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ssm_trajectory.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved as ssm_trajectory.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 3: How sequences from data become trajectories\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FROM SLIDING WINDOW SEQUENCES TO CONTINUOUS TRAJECTORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "YOUR DATA ORGANIZATION:\n",
    "═════════════════════════════════════════════════════════════════\n",
    "\n",
    "Raw data file:\n",
    "  u: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, ...]\n",
    "  y: [0.01, 0.04, 0.09, 0.16, 0.25, 0.36, 0.49, 0.64, 0.81, 1.0, ...]\n",
    "\n",
    "Sliding window (seq_len=3):\n",
    "  Sequence 0: u=[0.1, 0.2, 0.3]  → predict y[3]=0.16\n",
    "  Sequence 1: u=[0.2, 0.3, 0.4]  → predict y[4]=0.25\n",
    "  Sequence 2: u=[0.3, 0.4, 0.5]  → predict y[5]=0.36\n",
    "  ...\n",
    "\n",
    "But this OVERSAMPLE your data!\n",
    "\n",
    "\n",
    "BETTER: Use SSM to generate CONTINUOUS trajectory\n",
    "═════════════════════════════════════════════════════════════════\n",
    "\n",
    "1. Initialize x_0 = 0\n",
    "2. Feed full input sequence u = [u_0, u_1, ..., u_N]\n",
    "3. Iterate: x_{k+1} = A @ x_k + B @ u_k\n",
    "4. Collect output: y_k = C @ x_k\n",
    "\n",
    "Result: smooth trajectory without artificial windowing.\n",
    "\"\"\")\n",
    "\n",
    "# Real example with your data structure\n",
    "print(\"\\nPractical example with your data:\")\n",
    "print(f\"  Input file: {len(data_in_clean)} samples\")\n",
    "print(f\"  Output file: {len(data_out_clean)} samples\")\n",
    "\n",
    "# Use first 500 samples for demo\n",
    "u_demo = data_in_clean[:500, 0]\n",
    "print(f\"\\n  Taking first 500 input samples for trajectory generation...\")\n",
    "\n",
    "# Initialize SSM (you'd use your trained model here)\n",
    "# For now, use a simple identified system\n",
    "A_simple = np.array([[1.0, Ts], [0.0, 0.95]])\n",
    "B_simple = np.array([[0.0], [Ts]])\n",
    "C_simple = np.array([[0.0, 1.0]])\n",
    "\n",
    "y_ssm_demo, x_ssm_demo = ssm_trajectory(A_simple, B_simple, C_simple, u_demo)\n",
    "\n",
    "print(f\"\\n  SSM trajectory generated:\")\n",
    "print(f\"    Output shape: {y_ssm_demo.shape}\")\n",
    "print(f\"    Hidden state shape: {x_ssm_demo.shape}\")\n",
    "print(f\"    Max output: {np.max(np.abs(y_ssm_demo)):.4f}\")\n",
    "print(f\"    Min output: {np.min(np.abs(y_ssm_demo)):.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6))\n",
    "\n",
    "t_demo = np.arange(len(u_demo)) * Ts\n",
    "\n",
    "# Input\n",
    "axes[0].plot(t_demo, u_demo, 'b-', linewidth=1.5, alpha=0.7, label='Input (u_k)')\n",
    "axes[0].set_ylabel('Command Input')\n",
    "axes[0].set_title('Input Command Sequence')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Output trajectory\n",
    "axes[1].plot(t_demo, y_ssm_demo, 'r-', linewidth=1.5, alpha=0.7, label='SSM Output (y_k)')\n",
    "axes[1].set_ylabel('System Output')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_title('Generated Trajectory from SSM')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_to_trajectory.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved as data_to_trajectory.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE 4: For CONTROL (LQI): x means something different!\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPORTANT: x IS DIFFERENT FOR CONTROL!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "FOR PREDICTION (what we did above):\n",
    "──────────────────────────────────\n",
    "x = abstract latent state (learned by neural network)\n",
    "  - Dimension: 8 (arbitrary)\n",
    "  - Meaning: opaque\n",
    "  - Use: feed-forward prediction\n",
    "\n",
    "\n",
    "FOR CONTROL (LQI/LQR):\n",
    "──────────────────────\n",
    "x = physical state that YOU DEFINE\n",
    "  - Dimension: 2 (position z, velocity v)\n",
    "  - Meaning: explicit (z = altitude, v = vertical speed)\n",
    "  - Use: design feedback law u = -K(x - x_target)\n",
    "\n",
    "\n",
    "In your case for drone altitude:\n",
    "───────────────────────────────\n",
    "\n",
    "x_physical = [z, v]  where:\n",
    "  z = position (altitude)\n",
    "  v = velocity (vertical speed)\n",
    "\n",
    "You measure: a = acceleration\n",
    "You calculate (integrate):\n",
    "  v_{k+1} = v_k + a_k * Ts\n",
    "  z_{k+1} = z_k + v_k * Ts\n",
    "\n",
    "Then apply LQR:\n",
    "  u = -K @ [z - z_target, v]\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nSUMMARY TABLE:\")\n",
    "print(\"─\" * 80)\n",
    "print(f\"{'Context':<20} | {'x (state)':<20} | {'Purpose':<20}\")\n",
    "print(\"─\" * 80)\n",
    "print(f\"{'SSM Prediction':<20} | {'Latent 8D (abstract)':<20} | {'Forward model':<20}\")\n",
    "print(f\"{'LQI Control':<20} | {'Physical 2D (z, v)':<20} | {'Feedback law':<20}\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "# Concrete code example\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CODE EXAMPLE: Integrating measurements for control state\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "code_example = \"\"\"\n",
    "# Measured acceleration from drone IMU\n",
    "a_measured = 0.5  # m/s²\n",
    "\n",
    "# DRONE STATE for control purposes\n",
    "z = 5.0    # current altitude (m)\n",
    "v = 0.2    # current velocity (m/s)\n",
    "\n",
    "# CONTROL: u = -K @ [z - z_ref, v]\n",
    "z_ref = 10.0  # target altitude\n",
    "K = np.array([[100.0, 1.0]])  # LQR gain\n",
    "u = -K @ np.array([[z - z_ref], [v]])\n",
    "\n",
    "# INTEGRATE (next step)\n",
    "v_next = v + a_measured * Ts      # integrate acceleration\n",
    "z_next = z + v * Ts               # integrate velocity\n",
    "\n",
    "# HIDDEN STATE for SSM (if you use it too)\n",
    "# x_hidden = A_learned @ x_hidden + B_learned @ u\n",
    "# But this x_hidden is SEPARATE from [z, v]\n",
    "\"\"\"\n",
    "\n",
    "print(code_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL CLARITY: Your actual workflow\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"YOUR ACTUAL WORKFLOW FOR DRONE CONTROL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "workflow = \"\"\"\n",
    "PHASE 1: OFFLINE (on historical data)\n",
    "═════════════════════════════════════════════════════════════════\n",
    "\n",
    "Step 1a: Identify physical system\n",
    "  Input: bdd_in_mat_05.csv (commands), bdd_out_mat_05.csv (acceleration)\n",
    "  Process: Least-squares regression\n",
    "  Output: A_phys (2×2), B_phys (2×1) with interpretation:\n",
    "    A_phys = [[1, Ts],      ← position evolves to position + velocity\n",
    "              [0, 0.95]]     ← velocity decays with dynamics\n",
    "    B_phys = [[0],          ← acceleration doesn't directly affect position\n",
    "              [Ts]]         ← acceleration integrates into velocity\n",
    "\n",
    "Step 1b: Design LQR for physical system\n",
    "  Input: A_phys, B_phys, Q, R matrices\n",
    "  Process: Solve DARE\n",
    "  Output: K (1×2) gain\n",
    "    u = -K @ [z - z_ref, v]\n",
    "\n",
    "Step 1c (Optional): Train SSM for prediction\n",
    "  Input: Sliding window sequences (u_k window)\n",
    "  Process: Gradient descent on 8-dimensional latent space\n",
    "  Output: A_ssm (8×8), B_ssm (8×1), C_ssm (1×8)\n",
    "    (These are DIFFERENT from A_phys, B_phys!)\n",
    "\n",
    "\n",
    "PHASE 2: ONLINE (real-time on drone)\n",
    "═════════════════════════════════════════════════════════════════\n",
    "\n",
    "Step 2a: Initialize state\n",
    "  z = 0     (initial altitude)\n",
    "  v = 0     (initial velocity)\n",
    "  x_hidden = 0_8 (if using SSM)\n",
    "\n",
    "Step 2b: Measure acceleration\n",
    "  a = IMU.read()\n",
    "\n",
    "Step 2c: Design control input\n",
    "  Option A (pure LQR):\n",
    "    u = -K @ [z - z_ref, v]\n",
    "  \n",
    "  Option B (with SSM correction):\n",
    "    u_lqr = -K @ [z - z_ref, v]\n",
    "    # Also predict with SSM (for error correction)\n",
    "    x_hidden = A_ssm @ x_hidden + B_ssm @ u\n",
    "    a_pred = C_ssm @ x_hidden\n",
    "    error_correction = (a - a_pred) * gain\n",
    "    u = u_lqr + error_correction\n",
    "\n",
    "Step 2d: Send to actuator\n",
    "  motor.set(u)\n",
    "\n",
    "Step 2e: Integrate for next state\n",
    "  v_next = v + a * Ts\n",
    "  z_next = z + v * Ts\n",
    "  \n",
    "  x_hidden_next = A_ssm @ x_hidden + B_ssm @ u\n",
    "\n",
    "Step 2f: Update and repeat\n",
    "  z = z_next\n",
    "  v = v_next\n",
    "  x_hidden = x_hidden_next\n",
    "  goto Step 2b\n",
    "\n",
    "\n",
    "SUMMARY:\n",
    "════════\n",
    "For PREDICTION (forward model):\n",
    "  x_hidden ∈ ℝ⁸ (learned latent space)\n",
    "  \n",
    "For CONTROL (feedback law):\n",
    "  x_physical = [z, v] ∈ ℝ²  (your state)\n",
    "  \n",
    "For INTEGRATION (update dynamics):\n",
    "  z_{k+1} = z_k + v_k * Ts\n",
    "  v_{k+1} = v_k + a_k * Ts\n",
    "\"\"\"\n",
    "\n",
    "print(workflow)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
