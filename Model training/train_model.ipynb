{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab087cec",
   "metadata": {},
   "source": [
    "# Entraînement du Modèle de Dynamique du Drone\n",
    "\n",
    "Ce notebook:\n",
    "1. Charge les données d'entrée/sortie (séries temporelles)\n",
    "2. Prépare et normalise les données\n",
    "3. Entraîne un modèle (LSTM, GRU ou Transformer) au choix\n",
    "4. Évalue les performances\n",
    "5. Exporte le modèle pour utilisation dans le contrôleur MPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab1dfa",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc021981",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "\n",
    "**Format**: Chaque ligne = UNE série temporelle (séquence complète)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46084821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "data_in = np.loadtxt('bdd_in_mat_05.csv', delimiter=',')\n",
    "data_out = np.loadtxt('bdd_out_mat_05.csv', delimiter=',')\n",
    "\n",
    "print(f'Shape données entrée (inputs): {data_in.shape}')\n",
    "print(f'Shape données sortie (outputs): {data_out.shape}')\n",
    "print(f'Nombre de séries temporelles: {data_in.shape[0]}')\n",
    "print(f'Longueur de chaque série: {data_in.shape[1]}')\n",
    "\n",
    "# Afficher quelques statistiques\n",
    "print(f'\\nStats données entrée:')\n",
    "print(f'  Min: {data_in.min():.4f}, Max: {data_in.max():.4f}, Mean: {data_in.mean():.4f}')\n",
    "print(f'\\nStats données sortie:')\n",
    "print(f'  Min: {data_out.min():.4f}, Max: {data_out.max():.4f}, Mean: {data_out.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc05a09",
   "metadata": {},
   "source": [
    "## 3. Préparation des Données\n",
    "\n",
    "Créer des séquences chevauchantes (sliding window) pour l'entraînement séquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caaf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de séquence\n",
    "seq_length = 50  # Longueur des séquences d'entrée\n",
    "pred_steps = 1   # Nombre de pas à prédire (1 = prédiction 1 pas en avant)\n",
    "batch_size = 32\n",
    "train_ratio = 0.8\n",
    "\n",
    "def create_sequences(X, y, seq_len, pred_steps):\n",
    "    \"\"\"\n",
    "    Crée des séquences chevauchantes à partir des données.\n",
    "    \n",
    "    Args:\n",
    "        X: array (N_series, T) - données d'entrée\n",
    "        y: array (N_series, T) - données de sortie\n",
    "        seq_len: longueur des séquences d'entrée\n",
    "        pred_steps: nombre de pas à prédire\n",
    "    \n",
    "    Returns:\n",
    "        X_seq, y_seq: séquences pour l'entraînement\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for series_idx in range(X.shape[0]):\n",
    "        for t in range(X.shape[1] - seq_len - pred_steps + 1):\n",
    "            # Fenêtre d'entrée: [t, t+seq_len)\n",
    "            X_seq.append(X[series_idx, t:t+seq_len])\n",
    "            # Cible: sortie à t+seq_len\n",
    "            y_seq.append(y[series_idx, t+seq_len:t+seq_len+pred_steps])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Créer les séquences\n",
    "print('Création des séquences chevauchantes...')\n",
    "X_seq, y_seq = create_sequences(data_in, data_out, seq_length, pred_steps)\n",
    "print(f'X_seq shape: {X_seq.shape}')  # (N_samples, seq_length)\n",
    "print(f'y_seq shape: {y_seq.shape}')  # (N_samples, pred_steps)\n",
    "\n",
    "# Normalisation\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_seq_flat = X_seq.reshape(-1, 1)\n",
    "X_seq_norm = scaler_X.fit_transform(X_seq_flat).reshape(X_seq.shape)\n",
    "\n",
    "y_seq_flat = y_seq.reshape(-1, 1)\n",
    "y_seq_norm = scaler_y.fit_transform(y_seq_flat).reshape(y_seq.shape)\n",
    "\n",
    "print(f'\\nAprès normalisation:')\n",
    "print(f'X_seq_norm - Mean: {X_seq_norm.mean():.4f}, Std: {X_seq_norm.std():.4f}')\n",
    "print(f'y_seq_norm - Mean: {y_seq_norm.mean():.4f}, Std: {y_seq_norm.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5baa62e",
   "metadata": {},
   "source": [
    "## 4. Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "n_train = int(len(X_seq_norm) * train_ratio)\n",
    "X_train = X_seq_norm[:n_train]\n",
    "y_train = y_seq_norm[:n_train]\n",
    "X_test = X_seq_norm[n_train:]\n",
    "y_test = y_seq_norm[n_train:]\n",
    "\n",
    "print(f'Train set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n",
    "\n",
    "# Convertir en tensors PyTorch\n",
    "X_train_t = torch.FloatTensor(X_train).unsqueeze(-1).to(device)  # (N, seq_len, 1)\n",
    "y_train_t = torch.FloatTensor(y_train).to(device)                # (N, pred_steps)\n",
    "X_test_t = torch.FloatTensor(X_test).unsqueeze(-1).to(device)\n",
    "y_test_t = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "print(f'\\nX_train_t shape: {X_train_t.shape}')\n",
    "print(f'y_train_t shape: {y_train_t.shape}')\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2a0a8",
   "metadata": {},
   "source": [
    "## 5. Définition des Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"Modèle LSTM pour prédiction de séries temporelles\"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Utiliser la dernière sortie du LSTM\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_hidden)\n",
    "        return output\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"Modèle GRU pour prédiction de séries temporelles\"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_hidden = gru_out[:, -1, :]\n",
    "        output = self.fc(last_hidden)\n",
    "        return output\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Modèle Transformer pour prédiction de séries temporelles\"\"\"\n",
    "    def __init__(self, input_size=1, d_model=64, nhead=4, num_layers=2, output_size=1, seq_length=50):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, seq_length, d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=128, \n",
    "            dropout=0.2, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        x = self.embedding(x)\n",
    "        # Positional encoding\n",
    "        x = x + self.pos_encoder\n",
    "        # Transformer\n",
    "        trans_out = self.transformer(x)\n",
    "        # Utiliser le dernier token\n",
    "        last_hidden = trans_out[:, -1, :]\n",
    "        output = self.fc(last_hidden)\n",
    "        return output\n",
    "\n",
    "print('Modèles définis: LSTM, GRU, Transformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405727d",
   "metadata": {},
   "source": [
    "## 6. Sélection du Modèle et Paramètres d'Entraînement\n",
    "\n",
    "⬇️ **CHOISISSEZ ICI VOTRE MODÈLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CHOISIR LE MODÈLE ======\n",
    "MODEL_TYPE = 'LSTM'  # Options: 'LSTM', 'GRU', 'Transformer'\n",
    "\n",
    "# Hyperparamètres\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "# Créer le modèle\n",
    "if MODEL_TYPE == 'LSTM':\n",
    "    model = LSTMModel(input_size=1, hidden_size=hidden_size, num_layers=num_layers, output_size=1)\n",
    "elif MODEL_TYPE == 'GRU':\n",
    "    model = GRUModel(input_size=1, hidden_size=hidden_size, num_layers=num_layers, output_size=1)\n",
    "elif MODEL_TYPE == 'Transformer':\n",
    "    model = TransformerModel(input_size=1, d_model=hidden_size, nhead=4, num_layers=num_layers, \n",
    "                            output_size=1, seq_length=seq_length)\n",
    "else:\n",
    "    raise ValueError(f\"Modèle non reconnu: {MODEL_TYPE}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'Modèle: {MODEL_TYPE}')\n",
    "print(f'Nombre de paramètres: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'\\n{model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d395712",
   "metadata": {},
   "source": [
    "## 7. Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss et optimiseur\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Historique\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f'Entraînement sur {epochs} epochs...')\n",
    "print(f'Learning rate: {learning_rate}')\n",
    "print('-' * 60)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ====== TRAIN ======\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # ====== TEST ======\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1:3d}/{epochs} | Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}')\n",
    "\n",
    "print('-' * 60)\n",
    "print('✓ Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c20ae",
   "metadata": {},
   "source": [
    "## 8. Visualisation des Pertes d'Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2, alpha=0.8)\n",
    "plt.plot(test_losses, label='Test Loss', linewidth=2, alpha=0.8)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.title(f'Courbes d\\'entraînement - {MODEL_TYPE}', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'training_loss_{MODEL_TYPE}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Train Loss initial: {train_losses[0]:.6f}')\n",
    "print(f'Train Loss final:   {train_losses[-1]:.6f}')\n",
    "print(f'Test Loss initial:  {test_losses[0]:.6f}')\n",
    "print(f'Test Loss final:    {test_losses[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125649a",
   "metadata": {},
   "source": [
    "## 9. Évaluation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Prédictions train\n",
    "    y_train_pred_norm = model(X_train_t).cpu().numpy()\n",
    "    y_train_true_norm = y_train_t.cpu().numpy()\n",
    "    \n",
    "    # Prédictions test\n",
    "    y_test_pred_norm = model(X_test_t).cpu().numpy()\n",
    "    y_test_true_norm = y_test_t.cpu().numpy()\n",
    "\n",
    "# Inverse transform pour échelle originale\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_norm)\n",
    "y_train_true = scaler_y.inverse_transform(y_train_true_norm)\n",
    "y_test_pred = scaler_y.inverse_transform(y_test_pred_norm)\n",
    "y_test_true = scaler_y.inverse_transform(y_test_true_norm)\n",
    "\n",
    "# Métriques\n",
    "train_mse = mean_squared_error(y_train_true, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train_true, y_train_pred)\n",
    "train_r2 = r2_score(y_train_true, y_train_pred)\n",
    "\n",
    "test_mse = mean_squared_error(y_test_true, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "test_r2 = r2_score(y_test_true, y_test_pred)\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'MÉTRIQUES D\\'ÉVALUATION - {MODEL_TYPE}')\n",
    "print('=' * 60)\n",
    "print(f'\\nTRAIN SET:')\n",
    "print(f'  MSE:  {train_mse:.6f}')\n",
    "print(f'  MAE:  {train_mae:.6f}')\n",
    "print(f'  R²:   {train_r2:.6f}')\n",
    "print(f'\\nTEST SET:')\n",
    "print(f'  MSE:  {test_mse:.6f}')\n",
    "print(f'  MAE:  {test_mae:.6f}')\n",
    "print(f'  R²:   {test_r2:.6f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f756ef5",
   "metadata": {},
   "source": [
    "## 10. Visualisation des Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ===== Train vs Prédictions (Train) =====\n",
    "axes[0, 0].scatter(y_train_true, y_train_pred, alpha=0.5, s=20)\n",
    "axes[0, 0].plot([y_train_true.min(), y_train_true.max()], \n",
    "                [y_train_true.min(), y_train_true.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Vraie Valeur', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Prédiction', fontsize=11)\n",
    "axes[0, 0].set_title(f'Train Set (R² = {train_r2:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ===== Test vs Prédictions (Test) =====\n",
    "axes[0, 1].scatter(y_test_true, y_test_pred, alpha=0.5, s=20, color='orange')\n",
    "axes[0, 1].plot([y_test_true.min(), y_test_true.max()], \n",
    "               [y_test_true.min(), y_test_true.max()], \n",
    "               'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('Vraie Valeur', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Prédiction', fontsize=11)\n",
    "axes[0, 1].set_title(f'Test Set (R² = {test_r2:.4f})', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ===== Résidus (Train) =====\n",
    "residuals_train = y_train_true - y_train_pred\n",
    "axes[1, 0].hist(residuals_train, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[1, 0].axvline(0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Résidu', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Fréquence', fontsize=11)\n",
    "axes[1, 0].set_title(f'Distribution des Résidus Train (σ = {residuals_train.std():.4f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ===== Résidus (Test) =====\n",
    "residuals_test = y_test_true - y_test_pred\n",
    "axes[1, 1].hist(residuals_test, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1, 1].axvline(0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Résidu', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Fréquence', fontsize=11)\n",
    "axes[1, 1].set_title(f'Distribution des Résidus Test (σ = {residuals_test.std():.4f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'model_evaluation_{MODEL_TYPE}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfcc75",
   "metadata": {},
   "source": [
    "## 11. Séquences Temporelles - Quelques Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1332313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher quelques prédictions sur des séquences test\n",
    "n_examples = 5\n",
    "fig, axes = plt.subplots(n_examples, 1, figsize=(14, 12))\n",
    "\n",
    "indices = np.random.choice(len(y_test_true), n_examples, replace=False)\n",
    "\n",
    "for idx, i in enumerate(indices):\n",
    "    # Prédiction vs vrai\n",
    "    axes[idx].bar(['Vraie Valeur', 'Prédiction'], \n",
    "                   [y_test_true[i, 0], y_test_pred[i, 0]], \n",
    "                   color=['blue', 'orange'], alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    axes[idx].set_ylabel('Sortie (accélération)', fontsize=11)\n",
    "    axes[idx].set_title(f'Exemple {idx+1} - Erreur: {abs(y_test_true[i, 0] - y_test_pred[i, 0]):.6f}', fontsize=11)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'prediction_examples_{MODEL_TYPE}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc868a64",
   "metadata": {},
   "source": [
    "## 12. Exportation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd675f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire avec tous les éléments nécessaires\n",
    "export_dict = {\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'hidden_size': hidden_size,\n",
    "    'num_layers': num_layers,\n",
    "    'seq_length': seq_length,\n",
    "    'scaler_X_mean': scaler_X.mean_,\n",
    "    'scaler_X_scale': scaler_X.scale_,\n",
    "    'scaler_y_mean': scaler_y.mean_,\n",
    "    'scaler_y_scale': scaler_y.scale_,\n",
    "    'metrics': {\n",
    "        'train_mse': float(train_mse),\n",
    "        'train_mae': float(train_mae),\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_mse': float(test_mse),\n",
    "        'test_mae': float(test_mae),\n",
    "        'test_r2': float(test_r2)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarder\n",
    "model_filename = f'drone_model_{MODEL_TYPE}.pt'\n",
    "torch.save(export_dict, model_filename)\n",
    "print(f'✓ Modèle sauvegardé: {model_filename}')\n",
    "print(f'\\nTaille du fichier: {np.prod(export_dict[\"model_state_dict\"][list(export_dict[\"model_state_dict\"].keys())[0]].shape)} paramètres')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dcc64",
   "metadata": {},
   "source": [
    "## 13. Résumé du Modèle Exporté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9073ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('RÉSUMÉ - MODÈLE EXPORTÉ')\n",
    "print('='*70)\n",
    "print(f'\\nType de modèle: {MODEL_TYPE}')\n",
    "print(f'Fichier: {model_filename}')\n",
    "print(f'\\nArchitecture:')\n",
    "print(f'  - Taille cachée: {hidden_size}')\n",
    "print(f'  - Nombre de couches: {num_layers}')\n",
    "print(f'  - Longueur de séquence: {seq_length}')\n",
    "print(f'\\nPerformances:')\n",
    "print(f'  Test MAE: {test_mae:.6f}')\n",
    "print(f'  Test R²:  {test_r2:.6f}')\n",
    "print(f'\\nNormalisation stockée:')\n",
    "print(f'  - Scaler entrée (X): mean={scaler_X.mean_[0]:.6f}, scale={scaler_X.scale_[0]:.6f}')\n",
    "print(f'  - Scaler sortie (y): mean={scaler_y.mean_[0]:.6f}, scale={scaler_y.scale_[0]:.6f}')\n",
    "print(f'\\n✓ Le modèle est prêt à être utilisé dans le contrôleur MPC!')\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
